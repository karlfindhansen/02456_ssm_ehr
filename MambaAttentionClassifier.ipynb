{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VigXREV0sdsK","executionInfo":{"status":"ok","timestamp":1733383515947,"user_tz":-60,"elapsed":22468,"user":{"displayName":"Dang Viet Anh Nguyen","userId":"05501971383722565430"}},"outputId":"903449bd-3ff2-4ee2-dfc1-c5047f71e37f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","True\n"]}],"source":["from google.colab import drive\n","import os\n","drive.mount('/content/drive')\n","project_dir = '/content/drive/My Drive/ssm_ehr'\n","print(os.path.exists(project_dir))"]},{"cell_type":"code","source":["\n","print(os.getcwd())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hO-kAOqotHYo","executionInfo":{"status":"ok","timestamp":1733383548177,"user_tz":-60,"elapsed":239,"user":{"displayName":"Dang Viet Anh Nguyen","userId":"05501971383722565430"}},"outputId":"7cbe4cd0-ded8-47f4-a47b-d44b0932958b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu121\n","!pip uninstall mamba-ssm causal-conv1d\n","!pip install causal-conv1d && pip install mamba-ssm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OT70cV1KxKtC","outputId":"b778fd39-26bb-4fbc-b829-5ebee885bee3","executionInfo":{"status":"ok","timestamp":1733383789071,"user_tz":-60,"elapsed":239899,"user":{"displayName":"Dang Viet Anh Nguyen","userId":"05501971383722565430"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://download.pytorch.org/whl/cu121\n","Collecting torch==2.4.0\n","  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.0%2Bcu121-cp310-cp310-linux_x86_64.whl (799.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m799.1/799.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision==0.19.0\n","  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.0%2Bcu121-cp310-cp310-linux_x86_64.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchaudio==2.4.0\n","  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.0%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m855.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting triton==3.0.0 (from torch==2.4.0)\n","  Downloading https://download.pytorch.org/whl/triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.19.0) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.19.0) (11.0.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.6.77)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n","Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.23.4\n","    Uninstalling nvidia-nccl-cu12-2.23.4:\n","      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n","    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.7.77\n","    Uninstalling nvidia-curand-cu12-10.3.7.77:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n","    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n","      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n","    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n","    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n","    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n","      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n","    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n","    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.1+cu121\n","    Uninstalling torch-2.5.1+cu121:\n","      Successfully uninstalled torch-2.5.1+cu121\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.20.1+cu121\n","    Uninstalling torchvision-0.20.1+cu121:\n","      Successfully uninstalled torchvision-0.20.1+cu121\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 2.5.1+cu121\n","    Uninstalling torchaudio-2.5.1+cu121:\n","      Successfully uninstalled torchaudio-2.5.1+cu121\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.0+cu121 torchaudio-2.4.0+cu121 torchvision-0.19.0+cu121 triton-3.0.0\n","\u001b[33mWARNING: Skipping mamba-ssm as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping causal-conv1d as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0mCollecting causal-conv1d\n","  Downloading causal_conv1d-1.4.0.tar.gz (9.3 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from causal-conv1d) (2.4.0+cu121)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from causal-conv1d) (24.2)\n","Collecting ninja (from causal-conv1d)\n","  Downloading ninja-1.11.1.2-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (2024.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (12.1.105)\n","Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (3.0.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->causal-conv1d) (12.6.77)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->causal-conv1d) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->causal-conv1d) (1.3.0)\n","Downloading ninja-1.11.1.2-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: causal-conv1d\n","  Building wheel for causal-conv1d (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for causal-conv1d: filename=causal_conv1d-1.4.0-cp310-cp310-linux_x86_64.whl size=104867883 sha256=b5e7cf7e964b5e99275d97ba1e1b0ee4e3073f4593743ba1f1c6aa394a3008cc\n","  Stored in directory: /root/.cache/pip/wheels/e3/dd/4c/205f24e151736bd22f5980738dd10a19af6f093b6f4dcab006\n","Successfully built causal-conv1d\n","Installing collected packages: ninja, causal-conv1d\n","Successfully installed causal-conv1d-1.4.0 ninja-1.11.1.2\n","Collecting mamba-ssm\n","  Downloading mamba_ssm-2.2.2.tar.gz (85 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (2.4.0+cu121)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (24.2)\n","Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (1.11.1.2)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (0.8.0)\n","Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (3.0.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (4.46.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (2024.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->mamba-ssm) (12.6.77)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.26.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (1.26.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.20.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (4.66.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mamba-ssm) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (2024.8.30)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mamba-ssm) (1.3.0)\n","Building wheels for collected packages: mamba-ssm\n","  Building wheel for mamba-ssm (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mamba-ssm: filename=mamba_ssm-2.2.2-cp310-cp310-linux_x86_64.whl size=323988104 sha256=6b082468a6abb6f6bc50c99263f17c6c7f5a2e8f6b275ed7998b81fb25279229\n","  Stored in directory: /root/.cache/pip/wheels/57/7c/90/9f963468ecc3791e36e388f9e7b4a4e1e3f90fbb340055aa4d\n","Successfully built mamba-ssm\n","Installing collected packages: mamba-ssm\n","Successfully installed mamba-ssm-2.2.2\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from mamba_ssm import Mamba  # Assuming Mamba is installed\n","import math\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"],"metadata":{"id":"ozvbuj_15knF","executionInfo":{"status":"ok","timestamp":1733383815077,"user_tz":-60,"elapsed":6662,"user":{"displayName":"Dang Viet Anh Nguyen","userId":"05501971383722565430"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9c30384f-45d1-4ae6-b629-9da4183e8b46"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/selective_scan_interface.py:164: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n","  def forward(ctx, xz, conv1d_weight, conv1d_bias, x_proj_weight, delta_proj_weight,\n","/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/selective_scan_interface.py:240: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n","  def backward(ctx, dout):\n","/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/layer_norm.py:986: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n","  def forward(\n","/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1045: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n","  def backward(ctx, dout, *args):\n","/usr/local/lib/python3.10/dist-packages/mamba_ssm/distributed/tensor_parallel.py:26: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n","  def forward(ctx, x, weight, bias, process_group=None, sequence_parallel=True):\n","/usr/local/lib/python3.10/dist-packages/mamba_ssm/distributed/tensor_parallel.py:62: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n","  def backward(ctx, grad_output):\n","/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:758: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n","  def forward(ctx, zxbcdt, conv1d_weight, conv1d_bias, dt_bias, A, D, chunk_size, initial_states=None, seq_idx=None, dt_limit=(0.0, float(\"inf\")), return_final_states=False, activation=\"silu\",\n","/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:836: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n","  def backward(ctx, dout, *args):\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import average_precision_score"],"metadata":{"id":"TWn5NXaA4PQ-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        self.pe = pe.unsqueeze(0).to(device)  # Shape: (1, max_len, d_model)\n","\n","    def forward(self, x):\n","        return x + self.pe[:, :x.size(1), :]  # Add positional encoding\n","\n","\n","class MambaAttentionClassifier(nn.Module):\n","    def __init__(self, ts_feature_dim, static_feature_dim, hidden_dim, num_classes):\n","        \"\"\"\n","        Args:\n","            ts_feature_dim (int): Number of features in time-series data (e.g., 37).\n","            static_feature_dim (int): Number of features in static data (e.g., 8).\n","            hidden_dim (int): Dimension of hidden states in the model.\n","            num_classes (int): Number of output classes (e.g., 2 for binary classification).\n","        \"\"\"\n","        super(MambaAttentionClassifier, self).__init__()\n","\n","        # Time-series processing with Mamba\n","        self.positional_encoding = PositionalEncoding(d_model=ts_feature_dim)\n","        self.mamba_layer = Mamba(\n","            d_model=ts_feature_dim,  # Include time as an additional feature\n","            d_state=hidden_dim,         # Mamba's internal state size\n","            d_conv=4,                   # Convolution width for local dependencies\n","            expand=2                    # Expansion factor\n","        )\n","\n","        self.projection = nn.Linear(ts_feature_dim, hidden_dim)\n","        self.mamba_norm = nn.LayerNorm(hidden_dim)  # Layer normalization for stability\n","\n","\n","        # Multi-head attention\n","        self.multihead_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=4, batch_first=True)\n","\n","        # Static feature processing\n","        self.static_fc = nn.Linear(static_feature_dim, hidden_dim)\n","        self.static_norm = nn.LayerNorm(hidden_dim)\n","\n","        # Fully connected layers for classification\n","        self.classifier = nn.Sequential(\n","            nn.Linear(hidden_dim * 2, hidden_dim),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(hidden_dim, hidden_dim // 2),\n","            nn.ReLU(),\n","            nn.Linear(hidden_dim // 2, num_classes)\n","        )\n","\n","    def forward(self, ts_values, ts_indicators, ts_time, static):\n","        \"\"\"\n","        Args:\n","            ts_values (torch.Tensor): Time-series data (batch_size, seq_len, ts_feature_dim).\n","            ts_indicators (torch.Tensor): Indicator for missing time-series data (batch_size, seq_len, ts_feature_dim).\n","            ts_time (torch.Tensor): Time-series timestamps (batch_size, seq_len).\n","            static (torch.Tensor): Static features (batch_size, static_feature_dim).\n","        Returns:\n","            torch.Tensor: Class probabilities (batch_size, num_classes).\n","        \"\"\"\n","        # Ensure the shape of ts_indicators matches ts_values\n","        assert ts_values.shape == ts_indicators.shape, \"Shape mismatch between ts_values and ts_indicators\"\n","\n","        # Handle missing data: Mask out the missing time-series values using ts_indicators\n","        ts_values = ts_values * ts_indicators  # Element-wise multiplication to mask missing data\n","\n","        # Add time as an additional feature and apply positional encoding\n","        ts_time = ts_time.unsqueeze(-1)  # (batch_size, seq_len, 1)\n","        ts_combined = torch.cat([ts_values, ts_time], dim=-1)  # (batch_size, seq_len, ts_feature_dim + 1)\n","        ts_combined = self.positional_encoding(ts_combined)\n","\n","        # Process time-series data with Mamba\n","        ts_encoded = self.mamba_layer(ts_combined)  # (batch_size, seq_len, hidden_dim)\n","        ts_encoded = self.projection(ts_encoded)  # (batch_size, seq_len, hidden_dim)\n","        ts_encoded = self.mamba_norm(ts_encoded)  # Normalize the Mamba output\n","\n","\n","        # Apply multi-head attention\n","        ts_encoded, _ = self.multihead_attention(ts_encoded, ts_encoded, ts_encoded)\n","\n","        # Compute attention weights\n","        attn_weights = F.softmax(torch.mean(ts_encoded, dim=-1, keepdim=True), dim=1)  # (batch_size, seq_len, 1)\n","        ts_attended = torch.sum(attn_weights * ts_encoded, dim=1)  # (batch_size, hidden_dim)\n","\n","        # Process static features\n","        static_encoded = F.relu(self.static_fc(static))  # (batch_size, hidden_dim)\n","        static_encoded = self.static_norm(static_encoded)\n","\n","        # Concatenate attended time-series and static features\n","        combined = torch.cat([ts_attended, static_encoded], dim=1)  # (batch_size, hidden_dim * 2)\n","\n","        # Classification\n","        output = self.classifier(combined)  # (batch_size, num_classes)\n","\n","        return output\n"],"metadata":{"id":"O3Tm30CZylSa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","class MambaAttentionClassifier(nn.Module):\n","    def __init__(self, ts_feature_dim, static_feature_dim, hidden_dim, num_classes):\n","        \"\"\"\n","        Args:\n","            ts_feature_dim (int): Number of features in time-series data (e.g., 37).\n","            static_feature_dim (int): Number of features in static data (e.g., 8).\n","            hidden_dim (int): Dimension of hidden states in the model.\n","            num_classes (int): Number of output classes (e.g., 2 for binary classification).\n","        \"\"\"\n","        super(MambaAttentionClassifier, self).__init__()\n","\n","        # Time-series processing with Mamba\n","        self.mamba_layer = Mamba(\n","            d_model=ts_feature_dim,  # Include time as an additional feature\n","            d_state=hidden_dim,         # Mamba's internal state size\n","            d_conv=4,                   # Convolution width for local dependencies\n","            expand=2                    # Expansion factor\n","        )\n","\n","        # Static feature processing\n","        self.static_fc = nn.Linear(static_feature_dim, hidden_dim)\n","\n","        # Attention layer to weight time-series features\n","        self.attention = nn.Linear(ts_feature_dim, 1)\n","\n","        # Fully connected layers for classification\n","        self.classifier = nn.Sequential(\n","            nn.Linear(ts_feature_dim + hidden_dim, hidden_dim),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(hidden_dim, num_classes)\n","        )\n","\n","    def forward(self, ts_values, ts_indicators, ts_time, static):\n","      \"\"\"\n","      Args:\n","          ts_values (torch.Tensor): Time-series data (batch_size, seq_len, ts_feature_dim).\n","          ts_indicators (torch.Tensor): Indicator for missing time-series data (batch_size, seq_len, ts_feature_dim).\n","          ts_time (torch.Tensor): Time-series timestamps (batch_size, seq_len).\n","          static (torch.Tensor): Static features (batch_size, static_feature_dim).\n","      Returns:\n","          torch.Tensor: Class probabilities (batch_size, num_classes).\n","      \"\"\"\n","      # Ensure the shape of ts_indicators matches ts_values\n","      assert ts_values.shape == ts_indicators.shape, \"Shape mismatch between ts_values and ts_indicators\"\n","\n","      # Handle missing data: Mask out the missing time-series values using ts_indicators\n","      ts_values = ts_values * ts_indicators  # Element-wise multiplication to mask missing data\n","\n","      ts_time = ts_time.unsqueeze(-1)  # (batch_size, seq_len, 1)\n","      ts_combined = torch.cat([ts_values, ts_time], dim=-1)  # (batch_size, seq_len, ts_feature_dim + 1)\n","\n","      # Process time-series data with Mamba\n","      ts_encoded = self.mamba_layer(ts_combined)  # (batch_size, seq_len, hidden_dim)\n","\n","      # print('ts_encoded shape',ts_encoded.shape)\n","\n","      # Reshape ts_encoded for the attention layer\n","      batch_size, seq_len, hidden_dim = ts_encoded.shape\n","      ts_encoded_flat = ts_encoded.view(-1, hidden_dim)  # Flatten to (batch_size * seq_len, hidden_dim)\n","\n","      # Compute attention scores\n","      attn_scores = self.attention(ts_encoded_flat)  # (batch_size * seq_len, 1)\n","      attn_scores = attn_scores.view(batch_size, seq_len, 1)  # Reshape back to (batch_size, seq_len, 1)\n","\n","      # Compute attention weights\n","      attn_weights = F.softmax(attn_scores, dim=1)  # (batch_size, seq_len, 1)\n","\n","      # Apply attention weights to the Mamba output\n","      ts_attended = torch.sum(attn_weights * ts_encoded, dim=1)  # (batch_size, hidden_dim)\n","\n","      # Process static features\n","      static_encoded = F.relu(self.static_fc(static))  # (batch_size, hidden_dim)\n","\n","      # Concatenate attended time-series and static features\n","      combined = torch.cat([ts_attended, static_encoded], dim=1)  # (batch_size, hidden_dim * 2)\n","\n","      # print('ts_attended shape',ts_attended.shape)\n","      # print('static_encoded shape', static_encoded.shape)\n","      # print('combined shape', combined.shape)\n","\n","      # Classification\n","      output = self.classifier(combined)  # (batch_size, num_classes)\n","\n","      return output\n","\n"],"metadata":{"id":"UIG39zTTtHxv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","\n","        # Compute sine and cosine values separately\n","        pe[:, 0::2] = torch.sin(position * div_term[: (d_model + 1) // 2])  # Handle odd d_model for sine\n","        pe[:, 1::2] = torch.cos(position * div_term[: d_model // 2])  # Handle odd d_model for cosine\n","\n","        self.pe = pe.unsqueeze(0).to(device)  # Shape: (1, max_len, d_model)\n","\n","    def forward(self, x):\n","        return x + self.pe[:, :x.size(1), :]  # Add positional encoding\n","\n","\n","class MambaAttentionClassifier(nn.Module):\n","    def __init__(self, ts_feature_dim, static_feature_dim, hidden_dim, num_classes, max_time_steps=1000):\n","        \"\"\"\n","        Args:\n","            ts_feature_dim (int): Number of features in time-series data (e.g., 37).\n","            static_feature_dim (int): Number of features in static data (e.g., 8).\n","            hidden_dim (int): Dimension of hidden states in the model.\n","            num_classes (int): Number of output classes (e.g., 2 for binary classification).\n","            max_time_steps (int): Maximum number of time steps for time embedding.\n","        \"\"\"\n","        super(MambaAttentionClassifier, self).__init__()\n","\n","        # Time-series positional encoding\n","        self.positional_encoding = PositionalEncoding(d_model=ts_feature_dim)\n","\n","        # Time embedding for dynamic time features\n","        self.time_embedding = nn.Embedding(max_time_steps, ts_feature_dim)\n","\n","\n","        # Mamba layer with residual connection\n","        self.mamba_layer = Mamba(\n","            d_model=ts_feature_dim,  # Input feature dimension\n","            d_state=hidden_dim,      # Mamba's hidden state size\n","            d_conv=4,                # Convolution width\n","            expand=2                 # Expansion factor\n","        )\n","        self.projection = nn.Linear(ts_feature_dim, hidden_dim)\n","        self.mamba_norm = nn.LayerNorm(hidden_dim)\n","        self.mamba_dropout = nn.Dropout(0.3)\n","\n","        # Multi-head attention with residual connection\n","        self.multihead_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=4, dropout=0.2, batch_first=True)\n","\n","        # Learnable attention mechanism\n","        self.attention_layer = nn.Linear(hidden_dim, 1)\n","\n","        # Static feature encoder\n","        self.static_fc = nn.utils.weight_norm(nn.Linear(static_feature_dim, hidden_dim))\n","        self.static_norm = nn.LayerNorm(hidden_dim)\n","\n","        # Fully connected classifier\n","        self.classifier = nn.Sequential(\n","            nn.Linear(hidden_dim * 2, hidden_dim),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(hidden_dim, hidden_dim // 2),\n","            nn.ReLU(),\n","            nn.Linear(hidden_dim // 2, num_classes)\n","        )\n","\n","    def forward(self, ts_values, ts_indicators, ts_time, static):\n","        \"\"\"\n","        Args:\n","            ts_values (torch.Tensor): Time-series data (batch_size, seq_len, ts_feature_dim).\n","            ts_indicators (torch.Tensor): Indicator for missing time-series data (batch_size, seq_len, ts_feature_dim).\n","            ts_time (torch.Tensor): Time-series timestamps (batch_size, seq_len).\n","            static (torch.Tensor): Static features (batch_size, static_feature_dim).\n","        Returns:\n","            torch.Tensor: Class probabilities (batch_size, num_classes).\n","        \"\"\"\n","        # Ensure the shape of ts_indicators matches ts_values\n","        assert ts_values.shape == ts_indicators.shape, \"Shape mismatch between ts_values and ts_indicators\"\n","\n","        # Mask missing time-series values\n","        ts_values = ts_values * ts_indicators\n","\n","        # Add positional encoding and time embedding\n","        ts_time_embed = self.time_embedding(ts_time.long())  # (batch_size, seq_len, ts_feature_dim)\n","        ts_combined = ts_values + ts_time_embed  # Element-wise addition\n","        ts_combined = self.positional_encoding(ts_combined)\n","\n","        # Process time-series data with Mamba\n","        ts_encoded = self.mamba_layer(ts_combined)  # (batch_size, seq_len, hidden_dim)\n","\n","        ts_encoded = self.projection(ts_encoded)  # (batch_size, seq_len, hidden_dim)\n","\n","        ts_encoded = self.mamba_norm(ts_encoded)  # Normalize Mamba output\n","        ts_encoded = self.mamba_dropout(ts_encoded)  # Apply dropout\n","\n","        # Apply multi-head attention with residual connection\n","        attn_output, _ = self.multihead_attention(ts_encoded, ts_encoded, ts_encoded)\n","        ts_encoded = ts_encoded + attn_output  # Residual connection\n","\n","        # Compute learnable attention weights\n","        attn_scores = self.attention_layer(ts_encoded).squeeze(-1)  # (batch_size, seq_len)\n","        attn_weights = F.softmax(attn_scores, dim=1)  # (batch_size, seq_len)\n","        ts_attended = torch.sum(ts_encoded * attn_weights.unsqueeze(-1), dim=1)  # (batch_size, hidden_dim)\n","\n","        # Process static features\n","        static_encoded = F.relu(self.static_fc(static))  # (batch_size, hidden_dim)\n","        static_encoded = self.static_norm(static_encoded)\n","\n","        # Concatenate time-series and static features\n","        combined = torch.cat([ts_attended, static_encoded], dim=1)  # (batch_size, hidden_dim * 2)\n","\n","        # Classification\n","        output = self.classifier(combined)  # (batch_size, num_classes)\n","        return output"],"metadata":{"id":"zU1JAElcyRRp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# FINAL MODEL OF MULTIHEAD ATTENTION WITH MAMBA\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","\n","        # Compute sine and cosine values separately\n","        pe[:, 0::2] = torch.sin(position * div_term[: (d_model + 1) // 2])  # Handle odd d_model for sine\n","        pe[:, 1::2] = torch.cos(position * div_term[: d_model // 2])  # Handle odd d_model for cosine\n","\n","        self.pe = pe.unsqueeze(0).to(device)  # Shape: (1, max_len, d_model)\n","\n","    def forward(self, x):\n","        return x + self.pe[:, :x.size(1), :]  # Add positional encoding\n","\n","class MambaAttentionClassifier(nn.Module):\n","    def __init__(self, ts_feature_dim, static_feature_dim, hidden_dim, num_classes, max_time_steps=1000):\n","        super(MambaAttentionClassifier, self).__init__()\n","\n","        # Time-series positional encoding\n","        self.positional_encoding = PositionalEncoding(d_model=ts_feature_dim)\n","\n","        # Time embedding for dynamic time features\n","        self.time_embedding = nn.Embedding(max_time_steps, ts_feature_dim)\n","\n","        # First Mamba layer with residual connection\n","        self.mamba_layer1 = Mamba(\n","            d_model=ts_feature_dim,  # Input feature dimension\n","            d_state=hidden_dim,      # Mamba's hidden state size\n","            d_conv=4,                # Convolution width\n","            expand=2                 # Expansion factor\n","        )\n","\n","        # Second Mamba layer\n","        self.mamba_layer2 = Mamba(\n","            d_model=hidden_dim,      # Output of first Mamba layer\n","            d_state=hidden_dim,      # Mamba's hidden state size\n","            d_conv=4,\n","            expand=2\n","        )\n","\n","        self.projection = nn.Linear(ts_feature_dim, hidden_dim)\n","        self.mamba_norm1 = nn.LayerNorm(hidden_dim)\n","        self.mamba_norm2 = nn.LayerNorm(hidden_dim)\n","        self.mamba_dropout = nn.Dropout(0.3)\n","\n","        self.batch_norm = nn.BatchNorm1d(hidden_dim)\n","\n","        # Multi-head attention with residual connection\n","        self.multihead_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=4, dropout=0.2, batch_first=True)\n","\n","        # Learnable attention mechanism\n","        self.attention_layer = nn.Linear(hidden_dim, 1)\n","\n","        # Static feature encoder\n","        self.static_fc = nn.utils.weight_norm(nn.Linear(static_feature_dim, hidden_dim))\n","        self.static_norm = nn.LayerNorm(hidden_dim)\n","\n","        # Fully connected classifier\n","        self.classifier = nn.Sequential(\n","            nn.Linear(hidden_dim * 2, hidden_dim),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(hidden_dim, hidden_dim // 2),\n","            nn.ReLU(),\n","            nn.Linear(hidden_dim // 2, num_classes)\n","        )\n","\n","    def forward(self, ts_values, ts_indicators, ts_time, static):\n","        # Ensure the shape of ts_indicators matches ts_values\n","        assert ts_values.shape == ts_indicators.shape, \"Shape mismatch between ts_values and ts_indicators\"\n","\n","        # Mask missing time-series values\n","        ts_values = ts_values * ts_indicators\n","\n","        # Add positional encoding and time embedding\n","        ts_time_embed = self.time_embedding(ts_time.long())  # (batch_size, seq_len, ts_feature_dim)\n","        ts_combined = ts_values + ts_time_embed  # Element-wise addition\n","        ts_combined = self.positional_encoding(ts_combined)\n","\n","        # Process time-series data with the first Mamba layer\n","        ts_encoded = self.mamba_layer1(ts_combined)  # (batch_size, seq_len, hidden_dim)\n","        ts_encoded = self.projection(ts_encoded)  # (batch_size, seq_len, hidden_dim)\n","        ts_encoded = self.mamba_norm1(ts_encoded)  # Normalize Mamba output\n","        ts_encoded = self.mamba_dropout(ts_encoded)  # Apply dropout\n","\n","        # Process with the second Mamba layer\n","        ts_encoded = self.mamba_layer2(ts_encoded)  # (batch_size, seq_len, hidden_dim)\n","        ts_encoded = self.mamba_norm2(ts_encoded)  # Normalize second Mamba output\n","        ts_encoded = self.mamba_dropout(ts_encoded)  # Apply dropout again\n","\n","        ts_encoded = self.batch_norm(ts_encoded.transpose(1, 2)).transpose(1, 2)\n","\n","        # Apply multi-head attention with residual connection\n","        attn_output, _ = self.multihead_attention(ts_encoded, ts_encoded, ts_encoded)\n","        ts_encoded = ts_encoded + attn_output  # Residual connection\n","\n","        # Compute learnable attention weights\n","        attn_scores = self.attention_layer(ts_encoded).squeeze(-1)  # (batch_size, seq_len)\n","        attn_weights = F.softmax(attn_scores, dim=1)  # (batch_size, seq_len)\n","        ts_attended = torch.sum(ts_encoded * attn_weights.unsqueeze(-1), dim=1)  # (batch_size, hidden_dim)\n","\n","        # Process static features\n","        static_encoded = F.relu(self.static_fc(static))  # (batch_size, hidden_dim)\n","        static_encoded = self.static_norm(static_encoded)\n","\n","        # Concatenate attended time-series and static features\n","        combined = torch.cat([ts_attended, static_encoded], dim=1)  # (batch_size, hidden_dim * 2)\n","\n","        # Classification\n","        output = self.classifier(combined)  # (batch_size, num_classes)\n","        return output"],"metadata":{"id":"_mkx_nPa1nqi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class EnhancedMambaAttentionClassifier(nn.Module):\n","    def __init__(self, ts_feature_dim, static_feature_dim, hidden_dim, num_classes, max_time_steps=1000):\n","        super(EnhancedMambaAttentionClassifier, self).__init__()\n","\n","        # Time-series positional encoding\n","        self.positional_encoding = PositionalEncoding(d_model=ts_feature_dim)\n","\n","        # Time embedding for dynamic time features\n","        self.time_embedding = nn.Embedding(max_time_steps, ts_feature_dim)\n","\n","        # First Mamba layer\n","        self.mamba_layer1 = Mamba(\n","            d_model=ts_feature_dim,\n","            d_state=hidden_dim,\n","            d_conv=4,  # Wider convolution for better receptive fields\n","            expand=2\n","        )\n","\n","        # Second Mamba layer\n","        self.mamba_layer2 = Mamba(\n","            d_model=hidden_dim,\n","            d_state=hidden_dim,\n","            d_conv=4,\n","            expand=4  # Increase expansion factor for more non-linear capacity\n","        )\n","\n","        # Multi-head attention with residual connection\n","        self.multihead_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=8, dropout=0.2, batch_first=True)\n","\n","        # Learnable attention mechanism\n","        self.attention_layer = nn.Linear(hidden_dim, 1)\n","\n","        # Static feature encoder\n","        self.static_fc = nn.Sequential(\n","            nn.utils.weight_norm(nn.Linear(static_feature_dim, hidden_dim)),\n","            nn.ReLU(),\n","            nn.LayerNorm(hidden_dim)\n","        )\n","\n","        # Fully connected classifier\n","        self.classifier = nn.Sequential(\n","            nn.Linear(hidden_dim * 2, hidden_dim),\n","            nn.GELU(),  # Replace ReLU with GELU for smoother gradients\n","            nn.Dropout(0.4),\n","            nn.Linear(hidden_dim, hidden_dim // 2),\n","            nn.GELU(),\n","            nn.Linear(hidden_dim // 2, num_classes)\n","        )\n","\n","        # Additional layers and normalization\n","        self.projection = nn.Linear(ts_feature_dim, hidden_dim)\n","        self.mamba_norm1 = nn.LayerNorm(hidden_dim)\n","        self.mamba_norm2 = nn.LayerNorm(hidden_dim)\n","        self.mamba_dropout = nn.Dropout(0.3)\n","        self.batch_norm = nn.BatchNorm1d(hidden_dim)\n","\n","    def forward(self, ts_values, ts_indicators, ts_time, static):\n","        # Ensure the shape of ts_indicators matches ts_values\n","        assert ts_values.shape == ts_indicators.shape, \"Shape mismatch between ts_values and ts_indicators\"\n","\n","        # Mask missing time-series values\n","        ts_values = ts_values * ts_indicators\n","\n","        # Add positional encoding and time embedding\n","        ts_time_embed = self.time_embedding(ts_time.long())\n","        ts_combined = ts_values + ts_time_embed\n","        ts_combined = self.positional_encoding(ts_combined)\n","\n","        # Process time-series data with Mamba layers\n","        ts_encoded = self.mamba_layer1(ts_combined)\n","        ts_encoded = self.projection(ts_encoded)\n","        ts_encoded = self.mamba_norm1(ts_encoded)\n","        ts_encoded = self.mamba_dropout(ts_encoded)\n","\n","        ts_encoded = self.mamba_layer2(ts_encoded)\n","        ts_encoded = self.mamba_norm2(ts_encoded)\n","        ts_encoded = self.mamba_dropout(ts_encoded)\n","\n","        # Batch normalization for stability\n","        ts_encoded = self.batch_norm(ts_encoded.transpose(1, 2)).transpose(1, 2)\n","\n","        # Multi-head attention with residual connection\n","        attn_output, _ = self.multihead_attention(ts_encoded, ts_encoded, ts_encoded)\n","        ts_encoded = ts_encoded + attn_output\n","\n","        # Compute learnable attention weights\n","        attn_scores = self.attention_layer(ts_encoded).squeeze(-1)\n","        attn_weights = F.softmax(attn_scores, dim=1)\n","        ts_attended = torch.sum(ts_encoded * attn_weights.unsqueeze(-1), dim=1)\n","\n","        # Process static features\n","        static_encoded = self.static_fc(static)\n","\n","        # Concatenate attended time-series and static features\n","        combined = torch.cat([ts_attended, static_encoded], dim=1)\n","\n","        # Classification\n","        output = self.classifier(combined)\n","        return output"],"metadata":{"id":"yEG3SaOfwvan"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MoEMambaAttentionClassifier(nn.Module):\n","    def __init__(self, ts_feature_dim, static_feature_dim, hidden_dim, num_classes, num_experts=4, max_time_steps=1000):\n","        super(MoEMambaAttentionClassifier, self).__init__()\n","\n","        self.num_experts = num_experts\n","        self.hidden_dim = hidden_dim\n","\n","        # Gating network\n","        self.gating_network = nn.Sequential(\n","            nn.Linear(ts_feature_dim, num_experts),\n","            nn.Softmax(dim=-1)\n","        )\n","\n","        # Input projection to match hidden_dim\n","        self.input_projection = nn.Linear(ts_feature_dim, hidden_dim)\n","\n","        # Define experts (using Mamba layers here)\n","        self.experts = nn.ModuleList([\n","            nn.Sequential(\n","                Mamba(d_model=hidden_dim, d_state=hidden_dim, d_conv=4, expand=2),\n","                nn.LayerNorm(hidden_dim),\n","                nn.Dropout(0.3)\n","            )\n","            for _ in range(num_experts)\n","        ])\n","\n","        # Remaining layers (similar to your current model)\n","        self.projection = nn.Linear(hidden_dim, hidden_dim)\n","        self.multihead_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=4, dropout=0.2, batch_first=True)\n","        self.attention_layer = nn.Linear(hidden_dim, 1)\n","        self.static_fc = nn.utils.weight_norm(nn.Linear(static_feature_dim, hidden_dim))\n","        self.static_norm = nn.LayerNorm(hidden_dim)\n","        self.classifier = nn.Sequential(\n","            nn.Linear(hidden_dim * 2, hidden_dim),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(hidden_dim, hidden_dim // 2),\n","            nn.ReLU(),\n","            nn.Linear(hidden_dim // 2, num_classes)\n","        )\n","\n","    def forward(self, ts_values, ts_indicators, ts_time, static):\n","      # Mask missing time-series values\n","      ts_values = ts_values * ts_indicators\n","\n","      # Compute gating scores using the original ts_values (before projection)\n","      gating_scores = self.gating_network(ts_values.mean(dim=1))  # Shape: (batch_size, num_experts)\n","      gating_weights = F.softmax(gating_scores, dim=-1)  # Shape: (batch_size, num_experts)\n","\n","      # Project input to match hidden_dim for experts\n","      ts_values_projected = self.input_projection(ts_values)  # Shape: (batch_size, seq_len, hidden_dim)\n","\n","      # Expert outputs\n","      expert_outputs = []\n","      for i, expert in enumerate(self.experts):\n","          expert_output = expert(ts_values_projected)  # Shape: (batch_size, seq_len, hidden_dim)\n","          expert_outputs.append(expert_output)\n","      expert_outputs = torch.stack(expert_outputs, dim=1)  # Shape: (batch_size, num_experts, seq_len, hidden_dim)\n","\n","      # Combine expert outputs using gating weights\n","      ts_encoded = torch.einsum('be,besh->bsh', gating_weights, expert_outputs)  # Weighted sum\n","\n","      # Multi-head attention\n","      attn_output, _ = self.multihead_attention(ts_encoded, ts_encoded, ts_encoded)\n","      ts_encoded = ts_encoded + attn_output  # Residual connection\n","\n","      # Compute learnable attention weights\n","      attn_scores = self.attention_layer(ts_encoded).squeeze(-1)\n","      attn_weights = F.softmax(attn_scores, dim=1)\n","      ts_attended = torch.sum(ts_encoded * attn_weights.unsqueeze(-1), dim=1)\n","\n","      # Static features\n","      static_encoded = F.relu(self.static_fc(static))\n","      static_encoded = self.static_norm(static_encoded)\n","\n","      # Concatenate features\n","      combined = torch.cat([ts_attended, static_encoded], dim=1)\n","\n","      # Classification\n","      output = self.classifier(combined)\n","      return output\n"],"metadata":{"id":"j3VThDmaueHt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# FINAL MOE MAMBA ATTENTION\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","\n","        # Compute sine and cosine values separately\n","        pe[:, 0::2] = torch.sin(position * div_term[: (d_model + 1) // 2])  # Handle odd d_model for sine\n","        pe[:, 1::2] = torch.cos(position * div_term[: d_model // 2])  # Handle odd d_model for cosine\n","\n","        self.pe = pe.unsqueeze(0).to(device)  # Shape: (1, max_len, d_model)\n","\n","    def forward(self, x):\n","        return x + self.pe[:, :x.size(1), :]  # Add positional encoding\n","\n","class MoEMambaAttentionClassifier(nn.Module):\n","    def __init__(self, ts_feature_dim, static_feature_dim, hidden_dim, num_classes, num_experts=4, max_time_steps=1000):\n","        super(MoEMambaAttentionClassifier, self).__init__()\n","\n","        self.num_experts = num_experts\n","        self.hidden_dim = hidden_dim\n","\n","        # Time-series positional encoding\n","        self.positional_encoding = PositionalEncoding(d_model=ts_feature_dim)\n","\n","        # Time embedding for dynamic time features\n","        self.time_embedding = nn.Embedding(max_time_steps, ts_feature_dim)\n","\n","        # Gating network\n","        self.gating_network = nn.Sequential(\n","            nn.Linear(ts_feature_dim, num_experts),\n","            nn.Softmax(dim=-1)\n","        )\n","\n","        # Input projection to match hidden_dim\n","        self.input_projection = nn.Linear(ts_feature_dim, hidden_dim)\n","\n","        # Define experts (using Mamba layers here)\n","        self.experts = nn.ModuleList([\n","            nn.Sequential(\n","                Mamba(d_model=hidden_dim, d_state=hidden_dim, d_conv=4, expand=2),\n","                nn.LayerNorm(hidden_dim),\n","                nn.Dropout(0.3)\n","            )\n","            for _ in range(num_experts)\n","        ])\n","\n","        # Remaining layers (similar to your current model)\n","        self.projection = nn.Linear(hidden_dim, hidden_dim)\n","        self.multihead_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=4, dropout=0.2, batch_first=True)\n","        self.attention_layer = nn.Linear(hidden_dim, 1)\n","        self.static_fc = nn.utils.weight_norm(nn.Linear(static_feature_dim, hidden_dim))\n","        self.static_norm = nn.LayerNorm(hidden_dim)\n","        self.classifier = nn.Sequential(\n","            nn.Linear(hidden_dim * 2, hidden_dim),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(hidden_dim, hidden_dim // 2),\n","            nn.ReLU(),\n","            nn.Linear(hidden_dim // 2, num_classes)\n","        )\n","\n","    def forward(self, ts_values, ts_indicators, ts_time, static):\n","      # Mask missing time-series values\n","      ts_values = ts_values * ts_indicators\n","\n","\n","      # Add positional encoding and time embedding\n","      ts_time_embed = self.time_embedding(ts_time.long())\n","      ts_combined = ts_values + ts_time_embed\n","      ts_combined = self.positional_encoding(ts_combined)\n","\n","      # Compute gating scores using the original ts_values (before projection)\n","      gating_scores = self.gating_network(ts_combined.mean(dim=1))  # Shape: (batch_size, num_experts)\n","      gating_weights = F.softmax(gating_scores, dim=-1)  # Shape: (batch_size, num_experts)\n","\n","      # Project input to match hidden_dim for experts\n","      ts_combined_projected = self.input_projection(ts_combined)  # Shape: (batch_size, seq_len, hidden_dim)\n","\n","      # Expert outputs\n","      expert_outputs = []\n","      for i, expert in enumerate(self.experts):\n","          expert_output = expert(ts_combined_projected)  # Shape: (batch_size, seq_len, hidden_dim)\n","          expert_outputs.append(expert_output)\n","      expert_outputs = torch.stack(expert_outputs, dim=1)  # Shape: (batch_size, num_experts, seq_len, hidden_dim)\n","\n","      # Combine expert outputs using gating weights\n","      ts_encoded = torch.einsum('be,besh->bsh', gating_weights, expert_outputs)  # Weighted sum\n","\n","      # Multi-head attention\n","      attn_output, _ = self.multihead_attention(ts_encoded, ts_encoded, ts_encoded)\n","      ts_encoded = ts_encoded + attn_output  # Residual connection\n","\n","      # Compute learnable attention weights\n","      attn_scores = self.attention_layer(ts_encoded).squeeze(-1)\n","      attn_weights = F.softmax(attn_scores, dim=1)\n","      ts_attended = torch.sum(ts_encoded * attn_weights.unsqueeze(-1), dim=1)\n","\n","      # Static features\n","      static_encoded = F.relu(self.static_fc(static))\n","      static_encoded = self.static_norm(static_encoded)\n","\n","      # Concatenate features\n","      combined = torch.cat([ts_attended, static_encoded], dim=1)\n","\n","      # Classification\n","      output = self.classifier(combined)\n","      return output"],"metadata":{"id":"znSLoP9XfDNL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Ablation study\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term[: (d_model + 1) // 2])  # Handle odd d_model for sine\n","        pe[:, 1::2] = torch.cos(position * div_term[: d_model // 2])  # Handle odd d_model for cosine\n","        self.pe = pe.unsqueeze(0)\n","\n","    def forward(self, x):\n","        return x + self.pe[:, :x.size(1), :].to(x.device)\n","\n","\n","class MultiScaleAttention(nn.Module):\n","    def __init__(self, hidden_dim):\n","        super(MultiScaleAttention, self).__init__()\n","        self.short_term_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=4, dropout=0.2, batch_first=True)\n","        self.long_term_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=4, dropout=0.2, batch_first=True)\n","\n","    def forward(self, x):\n","        short_term_output, _ = self.short_term_attention(x, x, x)\n","        long_term_output, _ = self.long_term_attention(x, x, x)\n","        return torch.cat([short_term_output, long_term_output], dim=-1)\n","\n","\n","class ClassSpecificAttention(nn.Module):\n","    def __init__(self, hidden_dim, class_bias=2.0):\n","        super(ClassSpecificAttention, self).__init__()\n","        self.attention_layer = nn.Linear(hidden_dim, 1)\n","        self.class_bias = class_bias\n","\n","    def forward(self, x, labels=None):\n","        attn_scores = self.attention_layer(x).squeeze(-1)\n","        if labels is not None:\n","            attn_scores = attn_scores * (1 + self.class_bias * labels.unsqueeze(-1))\n","        attn_weights = F.softmax(attn_scores, dim=1)\n","        return torch.sum(x * attn_weights.unsqueeze(-1), dim=1)\n","\n","\n","class EnhancedMoEMambaAttentionClassifier(nn.Module):\n","    def __init__(self, ts_feature_dim, static_feature_dim, hidden_dim, num_classes, num_experts=4, max_time_steps=1000):\n","        super(EnhancedMoEMambaAttentionClassifier, self).__init__()\n","\n","        self.num_experts = num_experts\n","        self.hidden_dim = hidden_dim\n","\n","        # Positional encoding\n","        self.positional_encoding = PositionalEncoding(d_model=ts_feature_dim)\n","\n","        # Time embedding\n","        self.time_embedding = nn.Embedding(max_time_steps, ts_feature_dim)\n","\n","        # Gating network\n","        self.gating_network = nn.Sequential(\n","            nn.Linear(ts_feature_dim + hidden_dim, num_experts),\n","            nn.Softmax(dim=-1)\n","        )\n","\n","        # Input projection\n","        self.input_projection = nn.Linear(ts_feature_dim, hidden_dim)\n","\n","        # Heterogeneous experts\n","        self.experts = nn.ModuleList([\n","            nn.Sequential(\n","                nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1),\n","                nn.ReLU(),\n","                nn.LayerNorm(hidden_dim)  # Applies normalization after Conv1d\n","            ),\n","            nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=4, dim_feedforward=2 * hidden_dim, dropout=0.3),\n","            nn.Sequential(\n","                nn.Linear(hidden_dim, hidden_dim),\n","                nn.ReLU(),\n","                nn.LayerNorm(hidden_dim)\n","            ),\n","            nn.GRU(hidden_dim, hidden_dim, batch_first=True)  # Standalone GRU module\n","        ])\n","\n","        # Multi-scale attention\n","        self.multi_scale_attention = MultiScaleAttention(hidden_dim)\n","\n","        # Class-specific attention\n","        self.class_specific_attention = ClassSpecificAttention(hidden_dim * 2)\n","\n","        # Static feature encoder\n","        self.static_fc = nn.Sequential(\n","            nn.Linear(static_feature_dim, hidden_dim),\n","            nn.ReLU(),\n","            nn.LayerNorm(hidden_dim)\n","        )\n","\n","        # Classifier\n","        self.classifier = nn.Sequential(\n","            nn.Linear(hidden_dim * 3, hidden_dim),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(hidden_dim, num_classes)\n","        )\n","\n","    def forward(self, ts_values, ts_indicators, ts_time, static, labels=None):\n","        # Mask missing values\n","        ts_values = ts_values * ts_indicators\n","\n","        # Add positional encoding and time embedding\n","        ts_time_embed = self.time_embedding(ts_time.long())\n","        ts_combined = ts_values + ts_time_embed\n","        ts_combined = self.positional_encoding(ts_combined)\n","\n","        # Encode static features\n","        static_encoded = F.relu(self.static_fc(static))  # Shape: (batch_size, hidden_dim)\n","\n","        # Combine time-series and static features for gating network\n","        ts_mean = ts_combined.mean(dim=1)  # Shape: (batch_size, ts_feature_dim)\n","        combined_features = torch.cat([ts_mean, static_encoded], dim=-1)  # Shape: (batch_size, ts_feature_dim + hidden_dim)\n","\n","        # Gating network\n","        gating_scores = self.gating_network(combined_features)  # Shape: (batch_size, num_experts)\n","        gating_weights = F.softmax(gating_scores, dim=-1)\n","\n","        # Project input for experts\n","        ts_projected = self.input_projection(ts_combined)  # Shape: (batch_size, seq_len, hidden_dim)\n","\n","        # Expert outputs\n","        expert_outputs = []\n","        for expert in self.experts:\n","            if isinstance(expert, nn.Sequential):  # If the expert is a Sequential container\n","                if isinstance(expert[0], nn.Conv1d):  # Check if the first layer is Conv1d\n","                    conv_output = expert[0](ts_projected.transpose(1, 2))  # Apply Conv1d\n","                    conv_output = conv_output.transpose(1, 2)  # Transpose back to (batch_size, seq_len, hidden_dim)\n","                    expert_output = expert[1](conv_output)  # Apply subsequent layers\n","                else:\n","                    expert_output = expert(ts_projected)  # Apply the entire Sequential module\n","            elif isinstance(expert, nn.GRU):  # If the expert is GRU\n","                expert_output, _ = expert(ts_projected)  # Handle GRU output\n","            else:  # For standalone modules like TransformerEncoderLayer\n","                expert_output = expert(ts_projected)\n","            expert_outputs.append(expert_output)\n","        expert_outputs = torch.stack(expert_outputs, dim=1)  # Shape: (batch_size, num_experts, seq_len, hidden_dim)\n","\n","        # Combine expert outputs\n","        ts_encoded = torch.einsum('be,besh->bsh', gating_weights, expert_outputs)\n","\n","        # Apply multi-scale attention\n","        ts_attended = self.multi_scale_attention(ts_encoded)\n","\n","        # Apply class-specific attention\n","        ts_final = self.class_specific_attention(ts_attended, labels)\n","\n","        # Combine with static features\n","        combined = torch.cat([ts_final, static_encoded], dim=1)  # Shape: (batch_size, hidden_dim * 3)\n","\n","        # Classification\n","        output = self.classifier(combined)\n","        return output"],"metadata":{"id":"xANo7AngHIfU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SIGMOID\n","# FINAL MODEL OF MULTIHEAD ATTENTION WITH MAMBA\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","\n","        # Compute sine and cosine values separately\n","        pe[:, 0::2] = torch.sin(position * div_term[: (d_model + 1) // 2])  # Handle odd d_model for sine\n","        pe[:, 1::2] = torch.cos(position * div_term[: d_model // 2])  # Handle odd d_model for cosine\n","\n","        self.pe = pe.unsqueeze(0).to(device)  # Shape: (1, max_len, d_model)\n","\n","    def forward(self, x):\n","        return x + self.pe[:, :x.size(1), :]  # Add positional encoding\n","\n","class MambaAttentionClassifier(nn.Module):\n","    def __init__(self, ts_feature_dim, static_feature_dim, hidden_dim, num_classes, max_time_steps=1000):\n","        super(MambaAttentionClassifier, self).__init__()\n","\n","        # Time-series positional encoding\n","        self.positional_encoding = PositionalEncoding(d_model=ts_feature_dim)\n","\n","        # Time embedding for dynamic time features\n","        self.time_embedding = nn.Embedding(max_time_steps, ts_feature_dim)\n","\n","        # First Mamba layer with residual connection\n","        self.mamba_layer1 = Mamba(\n","            d_model=ts_feature_dim,  # Input feature dimension\n","            d_state=hidden_dim,      # Mamba's hidden state size\n","            d_conv=4,                # Convolution width\n","            expand=2                 # Expansion factor\n","        )\n","\n","        # Second Mamba layer\n","        self.mamba_layer2 = Mamba(\n","            d_model=hidden_dim,      # Output of first Mamba layer\n","            d_state=hidden_dim,      # Mamba's hidden state size\n","            d_conv=4,\n","            expand=2\n","        )\n","\n","        self.projection = nn.Linear(ts_feature_dim, hidden_dim)\n","        self.mamba_norm1 = nn.LayerNorm(hidden_dim)\n","        self.mamba_norm2 = nn.LayerNorm(hidden_dim)\n","        self.mamba_dropout = nn.Dropout(0.3)\n","\n","        self.batch_norm = nn.BatchNorm1d(hidden_dim)\n","\n","        # Multi-head attention with residual connection\n","        self.multihead_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=4, dropout=0.2, batch_first=True)\n","\n","        # Learnable attention mechanism\n","        self.attention_layer = nn.Linear(hidden_dim, 1)\n","\n","        # Static feature encoder\n","        self.static_fc = nn.utils.weight_norm(nn.Linear(static_feature_dim, hidden_dim))\n","        self.static_norm = nn.LayerNorm(hidden_dim)\n","\n","        # Fully connected classifier for binary output\n","        self.classifier = nn.Sequential(\n","            nn.Linear(hidden_dim * 2, hidden_dim),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(hidden_dim, 1),  # Single output for binary classification\n","            nn.Sigmoid()  # Sigmoid activation for binary probability\n","        )\n","\n","    def forward(self, ts_values, ts_indicators, ts_time, static):\n","        # Ensure the shape of ts_indicators matches ts_values\n","        assert ts_values.shape == ts_indicators.shape, \"Shape mismatch between ts_values and ts_indicators\"\n","\n","        # Mask missing time-series values\n","        ts_values = ts_values * ts_indicators\n","\n","        # Add positional encoding and time embedding\n","        ts_time_embed = self.time_embedding(ts_time.long())  # (batch_size, seq_len, ts_feature_dim)\n","        ts_combined = ts_values + ts_time_embed  # Element-wise addition\n","        ts_combined = self.positional_encoding(ts_combined)\n","\n","        # Process time-series data with the first Mamba layer\n","        ts_encoded = self.mamba_layer1(ts_combined)  # (batch_size, seq_len, hidden_dim)\n","        ts_encoded = self.projection(ts_encoded)  # (batch_size, seq_len, hidden_dim)\n","        ts_encoded = self.mamba_norm1(ts_encoded)  # Normalize Mamba output\n","        ts_encoded = self.mamba_dropout(ts_encoded)  # Apply dropout\n","\n","        # Process with the second Mamba layer\n","        ts_encoded = self.mamba_layer2(ts_encoded)  # (batch_size, seq_len, hidden_dim)\n","        ts_encoded = self.mamba_norm2(ts_encoded)  # Normalize second Mamba output\n","        ts_encoded = self.mamba_dropout(ts_encoded)  # Apply dropout again\n","\n","        ts_encoded = self.batch_norm(ts_encoded.transpose(1, 2)).transpose(1, 2)\n","\n","        # Apply multi-head attention with residual connection\n","        attn_output, _ = self.multihead_attention(ts_encoded, ts_encoded, ts_encoded)\n","        ts_encoded = ts_encoded + attn_output  # Residual connection\n","\n","        # Compute learnable attention weights\n","        attn_scores = self.attention_layer(ts_encoded).squeeze(-1)  # (batch_size, seq_len)\n","        attn_weights = F.softmax(attn_scores, dim=1)  # (batch_size, seq_len)\n","        ts_attended = torch.sum(ts_encoded * attn_weights.unsqueeze(-1), dim=1)  # (batch_size, hidden_dim)\n","\n","        # Process static features\n","        static_encoded = F.relu(self.static_fc(static))  # (batch_size, hidden_dim)\n","        static_encoded = self.static_norm(static_encoded)\n","\n","        # Concatenate attended time-series and static features\n","        combined = torch.cat([ts_attended, static_encoded], dim=1)  # (batch_size, hidden_dim * 2)\n","\n","        # Classification\n","        output = self.classifier(combined)  # (batch_size, num_classes)\n","        return output"],"metadata":{"id":"2JVXvlB4tDp3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# drive.mount('/content/drive')\n","# project_dir = '/content/drive/My Drive/ssm_ehr'\n","train_data = np.load('/content/drive/MyDrive/ssm_ehr/datasets/split_1/train_physionet2012_1.npy', allow_pickle=True)\n","test_data = np.load('/content/drive/MyDrive/ssm_ehr/datasets/split_1/test_physionet2012_1.npy', allow_pickle=True)\n","val_data = np.load('/content/drive/MyDrive/ssm_ehr/datasets/split_1/validation_physionet2012_1.npy', allow_pickle=True)"],"metadata":{"id":"rIwaoK-Gy0fx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def custom_collate_fn(batch):\n","    \"\"\"\n","    Custom collate function to handle batches with variable-length time-series data and static features.\n","\n","    Args:\n","        batch (list of tuples): Each tuple contains (ts_values, ts_indicators, ts_time, static, labels).\n","\n","    Returns:\n","        tuple: Padded time-series values, indicators, times, static features, and labels.\n","    \"\"\"\n","    ts_values = [sample[0].clone().detach().float() for sample in batch]\n","    ts_indicators = [sample[1].clone().detach().float() for sample in batch]\n","    ts_times = [sample[2].clone().detach().float() for sample in batch]\n","    static = torch.stack([sample[3].clone().detach().float() for sample in batch])\n","    labels = torch.tensor([sample[4] for sample in batch], dtype=torch.float32)\n","\n","    # Pad ts_values, ts_indicators, and ts_time\n","    ts_values_padded = pad_sequence(ts_values, batch_first=True)\n","    ts_indicators_padded = pad_sequence(ts_indicators, batch_first=True)\n","    ts_times_padded = pad_sequence(ts_times, batch_first=True)\n","\n","    return ts_values_padded, ts_indicators_padded, ts_times_padded, static, labels"],"metadata":{"id":"wsjLVeS-xTkG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","class ICUTimeSeriesDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        sample = self.data[idx]\n","        return (\n","            torch.tensor(sample['ts_values'], dtype=torch.float32),  # Time-series values\n","            torch.tensor(sample['ts_indicators'], dtype=torch.float32),  # Missing indicators\n","            torch.tensor(sample['ts_times'], dtype=torch.float32),  # Time steps\n","            torch.tensor(sample['static'], dtype=torch.float32),  # Static features\n","            torch.tensor(sample['labels'], dtype=torch.float32)  # Label\n","        )\n","\n","\n","train_dataset = ICUTimeSeriesDataset(train_data)\n","val_dataset = ICUTimeSeriesDataset(val_data)\n","test_dataset = ICUTimeSeriesDataset(test_data)\n","\n","# Dataloader\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=custom_collate_fn)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=custom_collate_fn)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=custom_collate_fn)"],"metadata":{"id":"3JIm0_MdxXIu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uIOckuB_0ZBp","executionInfo":{"status":"ok","timestamp":1733384005649,"user_tz":-60,"elapsed":215,"user":{"displayName":"Dang Viet Anh Nguyen","userId":"05501971383722565430"}},"outputId":"6e57c029-f575-460a-ea1f-19fa12ba2351"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# Define model\n","# model = MambaAttentionClassifier(\n","#     ts_feature_dim=37,\n","#     static_feature_dim=8,\n","#     hidden_dim=16,\n","#     num_classes=2\n","# )\n","\n","# model = EnhancedMambaAttentionClassifier(\n","#     ts_feature_dim=37,\n","#     static_feature_dim=8,\n","#     hidden_dim=16,\n","#     num_classes=2\n","# )\n","\n","\n","model = MoEMambaAttentionClassifier(\n","    ts_feature_dim=37,\n","    static_feature_dim=8,\n","    hidden_dim=16,\n","    num_classes=2\n",")\n","\n","# model = EnhancedMoEMambaAttentionClassifier(\n","#     ts_feature_dim=37,\n","#     static_feature_dim=8,\n","#     hidden_dim=16,\n","#     num_classes=2\n","# )\n","\n","def train(model, train_loader, val_loader, num_epochs = 100):\n","  model.to(device)\n","\n","  # Loss and optimizer\n","  criterion = nn.CrossEntropyLoss()\n","\n","  optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n","\n","  # Training loop\n","  train_losses = []\n","  val_losses = []\n","  for epoch in range(num_epochs):  # Adjust epochs as needed\n","      model.train()\n","      loss_train = 0\n","      for ts_values, ts_indicators, ts_time, static, labels in train_loader:\n","          ts_values,ts_indicators, ts_time , static, labels = ts_values.to(device), ts_indicators.to(device), ts_time.to(device), static.to(device), labels.to(device)\n","\n","          # Forward pass\n","          outputs = model(ts_values, ts_indicators, ts_time, static)\n","          loss = criterion(outputs, labels.long())\n","\n","          # Backward pass\n","          optimizer.zero_grad()\n","          loss.backward()\n","          torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Clip gradients\n","          optimizer.step()\n","\n","          loss_train += loss.item()\n","\n","      train_losses.append(loss_train/len(train_loader))\n","\n","      # validation loss\n","      model.eval().to(device)\n","      labels_list = torch.LongTensor([]).to(device)\n","      predictions_list = torch.FloatTensor([]).to(device)\n","      with torch.no_grad():\n","          for ts_values, ts_indicators, ts_time, static, labels in val_loader:\n","              ts_values,ts_indicators, ts_time, static, labels = ts_values.to(device), ts_indicators.to(device), ts_time.to(device), static.to(device), labels.to(device).long()\n","              labels_list = torch.cat((labels_list, labels), dim=0)\n","              predicition = model(ts_values, ts_indicators, ts_time, static)\n","              predictions_list = torch.cat((predictions_list, predicition), dim=0)\n","\n","          probs = torch.nn.functional.softmax(predictions_list, dim=1)\n","          auc_score = roc_auc_score(labels_list.cpu().numpy(), probs[:, 1].cpu().numpy())\n","          aupr_score = average_precision_score(labels_list.cpu().numpy(), probs[:, 1].cpu().numpy())\n","          accuracy = accuracy_score(labels_list.cpu().numpy(), (probs[:, 1] >= 0.5).cpu().numpy())\n","\n","      val_loss = criterion(predictions_list, labels_list)\n","      val_losses.append(val_loss)\n","      print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss_train/len(train_loader):.4f}, Val Loss: {val_loss:.4f}, AUC: {auc_score:.4f}, AUPR: {aupr_score:.4f}, Accuracy: {accuracy:.4f}\")\n","\n","  return model, train_losses, val_losses\n","\n","def test(model, test_loader):\n","    model.eval().to(device)  # Set model to evaluation mode\n","\n","    # Loss and metrics\n","    criterion = nn.CrossEntropyLoss()\n","    test_losses = []\n","    labels_list = torch.LongTensor([]).to(device)\n","    predictions_list = torch.FloatTensor([]).to(device)\n","\n","    with torch.no_grad():\n","        loss_test = 0\n","        for ts_values, ts_indicators, ts_time, static, labels in test_loader:\n","            # Move data to device\n","            ts_values, ts_indicators, ts_time, static, labels = (\n","                ts_values.to(device),\n","                ts_indicators.to(device),\n","                ts_time.to(device),\n","                static.to(device),\n","                labels.to(device).long(),\n","            )\n","\n","            # Forward pass\n","            predictions = model(ts_values, ts_indicators, ts_time, static)\n","            loss = criterion(predictions, labels)\n","\n","            # Accumulate test loss\n","            loss_test += loss.item()\n","\n","            # Collect labels and predictions for metrics\n","            labels_list = torch.cat((labels_list, labels), dim=0)\n","            predictions_list = torch.cat((predictions_list, predictions), dim=0)\n","\n","        # Compute average test loss\n","        test_losses.append(loss_test / len(test_loader))\n","\n","        # Compute probabilities for metrics\n","        probs = torch.nn.functional.softmax(predictions_list, dim=1)\n","        auc_score = roc_auc_score(labels_list.cpu().numpy(), probs[:, 1].cpu().numpy())\n","        aupr_score = average_precision_score(labels_list.cpu().numpy(), probs[:, 1].cpu().numpy())\n","        predicted_labels = (probs[:, 1] >= 0.5).cpu().numpy().astype(int)\n","        accuracy = accuracy_score(labels_list.cpu().numpy(), predicted_labels)\n","\n","    # Print test results\n","    print(f\"Test Loss: {test_losses[-1]:.4f}, AUC: {auc_score:.4f}, AUPR: {aupr_score:.4f}, Accuracy: {accuracy:.4f}\")\n","\n","    return test_losses, auc_score, aupr_score, accuracy\n","\n","model, train_losses, val_losses = train(model, train_loader, val_loader, 50)\n","print()\n","test_losses, auc_score, aupr_score, accuracy = test(model, test_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"id":"3RW--6rwxYj_","executionInfo":{"status":"error","timestamp":1733384047723,"user_tz":-60,"elapsed":221,"user":{"displayName":"Dang Viet Anh Nguyen","userId":"05501971383722565430"}},"outputId":"db9deb56-022a-41a0-94c3-71c4553a006b"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-90ad5685832e>\u001b[0m in \u001b[0;36m<cell line: 132>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtest_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maupr_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0mtest_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maupr_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-90ad5685832e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, num_epochs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0;31m# Loss and optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1172\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m     def register_full_backward_pre_hook(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1158\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m                     )\n\u001b[0;32m-> 1160\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1161\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"]}]},{"cell_type":"code","source":["class FocalLoss(nn.Module):\n","    def __init__(self, alpha=1, gamma=2):\n","        super(FocalLoss, self).__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","\n","    def forward(self, logits, targets):\n","        ce_loss = nn.CrossEntropyLoss(reduction='none')(logits, targets)\n","        pt = torch.exp(-ce_loss)\n","        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n","        return focal_loss.mean()"],"metadata":{"id":"pOw7tnL2Dncl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = MoEMambaAttentionClassifier(\n","    ts_feature_dim=37,\n","    static_feature_dim=8,\n","    hidden_dim=16,\n","    num_classes=2\n",")\n","def train(model, train_loader, val_loader, num_epochs=100):\n","    model.to(device)\n","\n","    # Focal loss or weighted loss\n","    criterion = FocalLoss(alpha=1.0, gamma=2.0)  # Alternatively, use CrossEntropyLoss with weights\n","\n","    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n","\n","    # Tracking metrics\n","    train_losses, val_losses = [], []\n","    best_aupr = 0  # To save the best model\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        loss_train = 0\n","        for ts_values, ts_indicators, ts_time, static, labels in train_loader:\n","            ts_values, ts_indicators, ts_time, static, labels = (\n","                ts_values.to(device),\n","                ts_indicators.to(device),\n","                ts_time.to(device),\n","                static.to(device),\n","                labels.to(device),\n","            )\n","\n","            # Forward pass\n","            outputs = model(ts_values, ts_indicators, ts_time, static)\n","            loss = criterion(outputs, labels.long())\n","\n","            # Backward pass\n","            optimizer.zero_grad()\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","            optimizer.step()\n","\n","            loss_train += loss.item()\n","\n","        train_losses.append(loss_train / len(train_loader))\n","\n","        # Validation\n","        model.eval()\n","        labels_list = torch.LongTensor([]).to(device)\n","        predictions_list = torch.FloatTensor([]).to(device)\n","        with torch.no_grad():\n","            for ts_values, ts_indicators, ts_time, static, labels in val_loader:\n","                ts_values, ts_indicators, ts_time, static, labels = (\n","                    ts_values.to(device),\n","                    ts_indicators.to(device),\n","                    ts_time.to(device),\n","                    static.to(device),\n","                    labels.to(device).long(),\n","                )\n","                labels_list = torch.cat((labels_list, labels), dim=0)\n","                predictions = model(ts_values, ts_indicators, ts_time, static)\n","                predictions_list = torch.cat((predictions_list, predictions), dim=0)\n","\n","        # Compute metrics\n","        probs = torch.nn.functional.softmax(predictions_list, dim=1)\n","        auc_score = roc_auc_score(labels_list.cpu().numpy(), probs[:, 1].cpu().numpy())\n","        aupr_score = average_precision_score(labels_list.cpu().numpy(), probs[:, 1].cpu().numpy())\n","        accuracy = accuracy_score(labels_list.cpu().numpy(), (probs[:, 1] >= 0.5).cpu().numpy())\n","\n","        val_loss = criterion(predictions_list, labels_list)\n","        val_losses.append(val_loss)\n","\n","        # Save the best model based on AUPRC\n","        if aupr_score > best_aupr:\n","            best_aupr = aupr_score\n","            best_model_state = model.state_dict()\n","            print(f\"New Best AUPRC: {best_aupr:.4f}\")\n","\n","        print(\n","            f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss_train/len(train_loader):.4f}, \"\n","            f\"Val Loss: {val_loss:.4f}, AUC: {auc_score:.4f}, AUPR: {aupr_score:.4f}, Accuracy: {accuracy:.4f}\"\n","        )\n","\n","    # Load best model\n","    model.load_state_dict(best_model_state)\n","    return model, train_losses, val_losses"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q7Ox6ojODl9J","executionInfo":{"status":"ok","timestamp":1733171680918,"user_tz":-60,"elapsed":4044,"user":{"displayName":"Dang Viet Anh Nguyen","userId":"05501971383722565430"}},"outputId":"083b7900-fd7a-4636-83e9-18a52e1572ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n","  WeightNorm.apply(module, name, dim)\n"]}]},{"cell_type":"code","source":["def test(model, test_loader):\n","    model.eval().to(device)  # Set model to evaluation mode\n","\n","    # Loss and metrics\n","    criterion = nn.CrossEntropyLoss()\n","    test_losses = []\n","    labels_list = torch.LongTensor([]).to(device)\n","    predictions_list = torch.FloatTensor([]).to(device)\n","\n","    with torch.no_grad():\n","        loss_test = 0\n","        for ts_values, ts_indicators, ts_time, static, labels in test_loader:\n","            # Move data to device\n","            ts_values, ts_indicators, ts_time, static, labels = (\n","                ts_values.to(device),\n","                ts_indicators.to(device),\n","                ts_time.to(device),\n","                static.to(device),\n","                labels.to(device).long(),\n","            )\n","\n","            # Forward pass\n","            predictions = model(ts_values, ts_indicators, ts_time, static)\n","            loss = criterion(predictions, labels)\n","\n","            # Accumulate test loss\n","            loss_test += loss.item()\n","\n","            # Collect labels and predictions for metrics\n","            labels_list = torch.cat((labels_list, labels), dim=0)\n","            predictions_list = torch.cat((predictions_list, predictions), dim=0)\n","\n","        # Compute average test loss\n","        test_losses.append(loss_test / len(test_loader))\n","\n","        # Compute probabilities for metrics\n","        probs = torch.nn.functional.softmax(predictions_list, dim=1)\n","        auc_score = roc_auc_score(labels_list.cpu().numpy(), probs[:, 1].cpu().numpy())\n","        aupr_score = average_precision_score(labels_list.cpu().numpy(), probs[:, 1].cpu().numpy())\n","        predicted_labels = (probs[:, 1] >= 0.5).cpu().numpy().astype(int)\n","        accuracy = accuracy_score(labels_list.cpu().numpy(), predicted_labels)\n","\n","    # Print test results\n","    print(f\"Test Loss: {test_losses[-1]:.4f}, AUC: {auc_score:.4f}, AUPR: {aupr_score:.4f}, Accuracy: {accuracy:.4f}\")\n","\n","    return test_losses, auc_score, aupr_score, accuracy\n","\n","model, train_losses, val_losses = train(model, train_loader, val_loader, 50)\n","print()\n","test_losses, auc_score, aupr_score, accuracy = test(model, test_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5G2tRXMkFKyX","executionInfo":{"status":"ok","timestamp":1733171996473,"user_tz":-60,"elapsed":315556,"user":{"displayName":"Dang Viet Anh Nguyen","userId":"05501971383722565430"}},"outputId":"e720795a-a042-4a85-e1f3-6d8164ec67e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["New Best AUPRC: 0.2024\n","Epoch [1/50], Train Loss: 0.1437, Val Loss: 0.1285, AUC: 0.5517, AUPR: 0.2024, Accuracy: 0.8390\n","New Best AUPRC: 0.2717\n","Epoch [2/50], Train Loss: 0.1144, Val Loss: 0.1138, AUC: 0.6417, AUPR: 0.2717, Accuracy: 0.8390\n","New Best AUPRC: 0.3151\n","Epoch [3/50], Train Loss: 0.1087, Val Loss: 0.1115, AUC: 0.6915, AUPR: 0.3151, Accuracy: 0.8390\n","New Best AUPRC: 0.3337\n","Epoch [4/50], Train Loss: 0.1054, Val Loss: 0.1087, AUC: 0.7192, AUPR: 0.3337, Accuracy: 0.8390\n","New Best AUPRC: 0.3418\n","Epoch [5/50], Train Loss: 0.1022, Val Loss: 0.1069, AUC: 0.7428, AUPR: 0.3418, Accuracy: 0.8390\n","New Best AUPRC: 0.3691\n","Epoch [6/50], Train Loss: 0.0988, Val Loss: 0.1020, AUC: 0.7687, AUPR: 0.3691, Accuracy: 0.8390\n","New Best AUPRC: 0.3713\n","Epoch [7/50], Train Loss: 0.0967, Val Loss: 0.0999, AUC: 0.7789, AUPR: 0.3713, Accuracy: 0.8390\n","New Best AUPRC: 0.3800\n","Epoch [8/50], Train Loss: 0.0947, Val Loss: 0.0991, AUC: 0.7852, AUPR: 0.3800, Accuracy: 0.8390\n","Epoch [9/50], Train Loss: 0.0944, Val Loss: 0.0980, AUC: 0.7871, AUPR: 0.3745, Accuracy: 0.8390\n","Epoch [10/50], Train Loss: 0.0940, Val Loss: 0.0976, AUC: 0.7899, AUPR: 0.3757, Accuracy: 0.8390\n","New Best AUPRC: 0.3815\n","Epoch [11/50], Train Loss: 0.0922, Val Loss: 0.0967, AUC: 0.7944, AUPR: 0.3815, Accuracy: 0.8390\n","New Best AUPRC: 0.3886\n","Epoch [12/50], Train Loss: 0.0922, Val Loss: 0.0960, AUC: 0.7984, AUPR: 0.3886, Accuracy: 0.8390\n","New Best AUPRC: 0.3954\n","Epoch [13/50], Train Loss: 0.0911, Val Loss: 0.0957, AUC: 0.8012, AUPR: 0.3954, Accuracy: 0.8382\n","New Best AUPRC: 0.4001\n","Epoch [14/50], Train Loss: 0.0914, Val Loss: 0.0952, AUC: 0.8035, AUPR: 0.4001, Accuracy: 0.8382\n","New Best AUPRC: 0.4018\n","Epoch [15/50], Train Loss: 0.0907, Val Loss: 0.0954, AUC: 0.8045, AUPR: 0.4018, Accuracy: 0.8382\n","New Best AUPRC: 0.4073\n","Epoch [16/50], Train Loss: 0.0900, Val Loss: 0.0944, AUC: 0.8076, AUPR: 0.4073, Accuracy: 0.8407\n","New Best AUPRC: 0.4095\n","Epoch [17/50], Train Loss: 0.0890, Val Loss: 0.0939, AUC: 0.8087, AUPR: 0.4095, Accuracy: 0.8390\n","Epoch [18/50], Train Loss: 0.0890, Val Loss: 0.0952, AUC: 0.8064, AUPR: 0.4084, Accuracy: 0.8399\n","New Best AUPRC: 0.4142\n","Epoch [19/50], Train Loss: 0.0888, Val Loss: 0.0936, AUC: 0.8113, AUPR: 0.4142, Accuracy: 0.8390\n","Epoch [20/50], Train Loss: 0.0886, Val Loss: 0.0933, AUC: 0.8118, AUPR: 0.4113, Accuracy: 0.8407\n","New Best AUPRC: 0.4196\n","Epoch [21/50], Train Loss: 0.0878, Val Loss: 0.0934, AUC: 0.8123, AUPR: 0.4196, Accuracy: 0.8399\n","New Best AUPRC: 0.4231\n","Epoch [22/50], Train Loss: 0.0873, Val Loss: 0.0929, AUC: 0.8144, AUPR: 0.4231, Accuracy: 0.8407\n","Epoch [23/50], Train Loss: 0.0866, Val Loss: 0.0932, AUC: 0.8136, AUPR: 0.4225, Accuracy: 0.8407\n","Epoch [24/50], Train Loss: 0.0871, Val Loss: 0.0932, AUC: 0.8127, AUPR: 0.4224, Accuracy: 0.8415\n","Epoch [25/50], Train Loss: 0.0863, Val Loss: 0.0928, AUC: 0.8127, AUPR: 0.4215, Accuracy: 0.8415\n","New Best AUPRC: 0.4246\n","Epoch [26/50], Train Loss: 0.0867, Val Loss: 0.0927, AUC: 0.8150, AUPR: 0.4246, Accuracy: 0.8424\n","New Best AUPRC: 0.4250\n","Epoch [27/50], Train Loss: 0.0858, Val Loss: 0.0935, AUC: 0.8135, AUPR: 0.4250, Accuracy: 0.8432\n","New Best AUPRC: 0.4272\n","Epoch [28/50], Train Loss: 0.0857, Val Loss: 0.0923, AUC: 0.8154, AUPR: 0.4272, Accuracy: 0.8432\n","New Best AUPRC: 0.4299\n","Epoch [29/50], Train Loss: 0.0850, Val Loss: 0.0923, AUC: 0.8160, AUPR: 0.4299, Accuracy: 0.8440\n","New Best AUPRC: 0.4321\n","Epoch [30/50], Train Loss: 0.0844, Val Loss: 0.0926, AUC: 0.8151, AUPR: 0.4321, Accuracy: 0.8465\n","New Best AUPRC: 0.4334\n","Epoch [31/50], Train Loss: 0.0843, Val Loss: 0.0923, AUC: 0.8161, AUPR: 0.4334, Accuracy: 0.8449\n","Epoch [32/50], Train Loss: 0.0835, Val Loss: 0.0935, AUC: 0.8145, AUPR: 0.4307, Accuracy: 0.8449\n","New Best AUPRC: 0.4345\n","Epoch [33/50], Train Loss: 0.0841, Val Loss: 0.0926, AUC: 0.8167, AUPR: 0.4345, Accuracy: 0.8449\n","Epoch [34/50], Train Loss: 0.0837, Val Loss: 0.0925, AUC: 0.8169, AUPR: 0.4331, Accuracy: 0.8465\n","New Best AUPRC: 0.4352\n","Epoch [35/50], Train Loss: 0.0834, Val Loss: 0.0928, AUC: 0.8146, AUPR: 0.4352, Accuracy: 0.8465\n","New Best AUPRC: 0.4364\n","Epoch [36/50], Train Loss: 0.0835, Val Loss: 0.0924, AUC: 0.8144, AUPR: 0.4364, Accuracy: 0.8465\n","Epoch [37/50], Train Loss: 0.0826, Val Loss: 0.0922, AUC: 0.8143, AUPR: 0.4346, Accuracy: 0.8465\n","New Best AUPRC: 0.4379\n","Epoch [38/50], Train Loss: 0.0827, Val Loss: 0.0932, AUC: 0.8144, AUPR: 0.4379, Accuracy: 0.8465\n","New Best AUPRC: 0.4391\n","Epoch [39/50], Train Loss: 0.0826, Val Loss: 0.0931, AUC: 0.8144, AUPR: 0.4391, Accuracy: 0.8465\n","Epoch [40/50], Train Loss: 0.0812, Val Loss: 0.0925, AUC: 0.8150, AUPR: 0.4366, Accuracy: 0.8449\n","Epoch [41/50], Train Loss: 0.0815, Val Loss: 0.0924, AUC: 0.8143, AUPR: 0.4364, Accuracy: 0.8465\n","Epoch [42/50], Train Loss: 0.0815, Val Loss: 0.0920, AUC: 0.8156, AUPR: 0.4386, Accuracy: 0.8399\n","Epoch [43/50], Train Loss: 0.0815, Val Loss: 0.0924, AUC: 0.8128, AUPR: 0.4370, Accuracy: 0.8457\n","Epoch [44/50], Train Loss: 0.0807, Val Loss: 0.0930, AUC: 0.8135, AUPR: 0.4377, Accuracy: 0.8440\n","New Best AUPRC: 0.4431\n","Epoch [45/50], Train Loss: 0.0805, Val Loss: 0.0919, AUC: 0.8153, AUPR: 0.4431, Accuracy: 0.8440\n","Epoch [46/50], Train Loss: 0.0801, Val Loss: 0.0920, AUC: 0.8144, AUPR: 0.4412, Accuracy: 0.8457\n","Epoch [47/50], Train Loss: 0.0805, Val Loss: 0.0928, AUC: 0.8141, AUPR: 0.4417, Accuracy: 0.8474\n","Epoch [48/50], Train Loss: 0.0793, Val Loss: 0.0932, AUC: 0.8110, AUPR: 0.4358, Accuracy: 0.8449\n","New Best AUPRC: 0.4435\n","Epoch [49/50], Train Loss: 0.0796, Val Loss: 0.0929, AUC: 0.8146, AUPR: 0.4435, Accuracy: 0.8465\n","New Best AUPRC: 0.4475\n","Epoch [50/50], Train Loss: 0.0793, Val Loss: 0.0926, AUC: 0.8162, AUPR: 0.4475, Accuracy: 0.8465\n","\n","Test Loss: 0.4212, AUC: 0.8308, AUPR: 0.4879, Accuracy: 0.8699\n"]}]},{"cell_type":"code","source":["\n","import matplotlib.pyplot as plt\n","\n","def plot_losses(train_losses, validation_losses):\n","    # Convert validation_losses to CPU and detach before plotting\n","    validation_losses = [v.cpu().detach().numpy() for v in validation_losses]\n","\n","    # Set the figure size and style\n","    plt.figure(figsize=(10, 6))\n","\n","    # Plot training loss with markers\n","    plt.plot(train_losses, label='Training Loss', color='tab:blue', marker='o', markersize=6, linestyle='-', linewidth=2)\n","\n","    # Plot validation loss with markers and different style\n","    plt.plot(validation_losses, label='Validation Loss', color='tab:orange', marker='s', markersize=6, linestyle='--', linewidth=2)\n","\n","    # Add labels, title, and legend with improved styles\n","    plt.xlabel('Epochs', fontsize=14, fontweight='bold')\n","    plt.ylabel('Loss', fontsize=14, fontweight='bold')\n","    plt.title('Training and Validation Loss Over Epochs', fontsize=16, fontweight='bold')\n","\n","    # Display the legend with adjusted positioning\n","    plt.legend(loc='upper right', fontsize=12)\n","\n","    # Adjust x and y ticks for better readability\n","    plt.xticks(fontsize=12)\n","    plt.yticks(fontsize=12)\n","\n","    # Show the plot\n","    plt.tight_layout()\n","    plt.show()\n","\n","plot_losses(train_losses, val_losses)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":607},"id":"CyhIE_D96ACJ","executionInfo":{"status":"ok","timestamp":1732964138082,"user_tz":-60,"elapsed":1771,"user":{"displayName":"Dang Viet Anh Nguyen","userId":"05501971383722565430"}},"outputId":"5fb227d2-fe0b-4afe-be3e-b6b6631d7dfa"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# Evaluation loop\n","model.eval()\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for ts_values, ts_indicators, ts_time, static, labels in val_loader:\n","        ts_values,ts_indicators,ts_time, static, labels = ts_values.to(device), ts_indicators.to(device),ts_time.to(device), static.to(device), labels.to(device)\n","        outputs = model(ts_values, ts_indicators,ts_time, static)\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels.long()).sum().item()\n","\n","    print(f\"Validation Accuracy: {100 * correct / total:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o6WTtyoNxZ2G","executionInfo":{"status":"ok","timestamp":1732549709015,"user_tz":-60,"elapsed":253,"user":{"displayName":"Dang Viet Anh Nguyen","userId":"05501971383722565430"}},"outputId":"d570347a-e877-417c-cd85-0424ef747848"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 84.57%\n"]}]},{"cell_type":"code","source":["def evaluate_model(model, data_loader, device):\n","    \"\"\"\n","    Evaluates the model on the given data loader and calculates evaluation metrics.\n","\n","    Args:\n","        model (torch.nn.Module): Trained model.\n","        data_loader (torch.utils.data.DataLoader): Data loader for validation/test set.\n","        device (torch.device): Device to perform computation on (CPU/GPU).\n","\n","    Returns:\n","        dict: A dictionary containing evaluation metrics.\n","    \"\"\"\n","    model.eval()  # Set model to evaluation mode\n","    y_true = []\n","    y_pred = []\n","    y_prob = []\n","\n","    with torch.no_grad():\n","        for ts_values, ts_indicators, ts_time, static, labels in data_loader:\n","            # Move data to device\n","            ts_values,ts_indicators, ts_time, static, labels = ts_values.to(device), ts_indicators.to(device), ts_time.to(device), static.to(device), labels.to(device)\n","\n","            # Get model predictions\n","            outputs = model(ts_values, ts_indicators, ts_time, static)  # Raw logits\n","            probabilities = torch.softmax(outputs, dim=1)[:, 1]  # Probability for class 1\n","            predictions = torch.argmax(outputs, dim=1)  # Predicted class labels\n","\n","            # Collect predictions and ground truth\n","            y_true.extend(labels.cpu().numpy())\n","            y_pred.extend(predictions.cpu().numpy())\n","            y_prob.extend(probabilities.cpu().numpy())\n","\n","    # Calculate evaluation metrics\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred, zero_division=1)\n","    recall = recall_score(y_true, y_pred, zero_division=1)\n","    f1 = f1_score(y_true, y_pred, zero_division=1)\n","    roc_auc = roc_auc_score(y_true, y_prob)\n","\n","    return {\n","        \"Accuracy\": accuracy,\n","        \"Precision\": precision,\n","        \"Recall\": recall,\n","        \"F1-Score\": f1,\n","        \"ROC-AUC\": roc_auc,\n","    }"],"metadata":{"id":"21P4H7sdxbFH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate on the validation or test set\n","metrics = evaluate_model(model, val_loader, device)\n","\n","# Print metrics\n","for metric, value in metrics.items():\n","    print(f\"{metric}: {value:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nRKLRIpQxcWP","executionInfo":{"status":"ok","timestamp":1732540960016,"user_tz":-60,"elapsed":2097,"user":{"displayName":"Dang Viet Anh Nguyen","userId":"05501971383722565430"}},"outputId":"4193bbf9-1cda-4342-fda6-a69f626a0039"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9916\n","Precision: 0.9612\n","Recall: 0.9791\n","F1-Score: 0.9701\n","ROC-AUC: 0.9992\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"u8Z_uymw9s0x"},"execution_count":null,"outputs":[]}]}