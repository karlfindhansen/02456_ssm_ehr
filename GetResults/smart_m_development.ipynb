{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FRDDPBfKic3h"
   },
   "source": [
    "# Development Notebook for 02456: Deep Learning @ DTU\n",
    "- Project 24: **Deep State Space Model for Mortality Classification using Electronic Health Records**\n",
    "- Supervised by Rachael Marie De Vries (rachael.devries@bio.ku.dk)\n",
    "\n",
    "\n",
    "Below is the development process for our final *SMART-M* model. Please note that this notebook must be run in colab, and there are a few lines that must be altered (filepaths etc).\n",
    "\n",
    "More information can be found in the `readme`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VigXREV0sdsK",
    "outputId": "d68b57b3-ee87-4c6b-e286-b1237f75586c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "drive.mount('/content/drive')\n",
    "project_dir = '/content/drive/My Drive/ssm_ehr' # CHANGE THIS ACCORDINGLY\n",
    "print(os.path.exists(project_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OT70cV1KxKtC",
    "outputId": "ea8c46ef-0333-433f-927d-6e4bcd92218b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Collecting torch==2.4.0\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.0%2Bcu121-cp310-cp310-linux_x86_64.whl (799.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m799.1/799.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchvision==0.19.0\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.0%2Bcu121-cp310-cp310-linux_x86_64.whl (7.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio==2.4.0\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.0%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (2024.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==3.0.0 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.19.0) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.19.0) (11.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.6.85)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
      "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
      "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
      "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n",
      "    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1+cu121\n",
      "    Uninstalling torch-2.5.1+cu121:\n",
      "      Successfully uninstalled torch-2.5.1+cu121\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.20.1+cu121\n",
      "    Uninstalling torchvision-0.20.1+cu121:\n",
      "      Successfully uninstalled torchvision-0.20.1+cu121\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.5.1+cu121\n",
      "    Uninstalling torchaudio-2.5.1+cu121:\n",
      "      Successfully uninstalled torchaudio-2.5.1+cu121\n",
      "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.0+cu121 torchaudio-2.4.0+cu121 torchvision-0.19.0+cu121 triton-3.0.0\n",
      "\u001b[33mWARNING: Skipping mamba-ssm as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping causal-conv1d as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting causal-conv1d\n",
      "  Downloading causal_conv1d-1.5.0.post8.tar.gz (9.4 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from causal-conv1d) (2.4.0+cu121)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from causal-conv1d) (24.2)\n",
      "Collecting ninja (from causal-conv1d)\n",
      "  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->causal-conv1d) (12.6.85)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->causal-conv1d) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->causal-conv1d) (1.3.0)\n",
      "Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: causal-conv1d\n",
      "  Building wheel for causal-conv1d (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for causal-conv1d: filename=causal_conv1d-1.5.0.post8-cp310-cp310-linux_x86_64.whl size=103955196 sha256=0ca2375ba7fb0c5022696dc3086c284e0eb1a7b33cf57aced23ec726c3d2b0a5\n",
      "  Stored in directory: /root/.cache/pip/wheels/75/ef/0a/d9abf869acdd5fc07f403f4d8dd9db650cd66e81528a907941\n",
      "Successfully built causal-conv1d\n",
      "Installing collected packages: ninja, causal-conv1d\n",
      "Successfully installed causal-conv1d-1.5.0.post8 ninja-1.11.1.3\n",
      "Collecting mamba-ssm\n",
      "  Downloading mamba_ssm-2.2.4.tar.gz (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (2.4.0+cu121)\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (1.11.1.3)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (0.8.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (4.47.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (24.2)\n",
      "Requirement already satisfied: setuptools>=61.0.0 in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (75.1.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->mamba-ssm) (12.6.85)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (1.26.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (4.67.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mamba-ssm) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (2024.12.14)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mamba-ssm) (1.3.0)\n",
      "Building wheels for collected packages: mamba-ssm\n",
      "  Building wheel for mamba-ssm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for mamba-ssm: filename=mamba_ssm-2.2.4-cp310-cp310-linux_x86_64.whl size=323653202 sha256=c6edff068928b4ceacc6e820a163908c02294fe01dbcc05e95ed4530a5f81e77\n",
      "  Stored in directory: /root/.cache/pip/wheels/aa/af/c7/fb77bfcd94bd3e052545033449d8c47dc97222d79c39c5bc67\n",
      "Successfully built mamba-ssm\n",
      "Installing collected packages: mamba-ssm\n",
      "Successfully installed mamba-ssm-2.2.4\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip uninstall mamba-ssm causal-conv1d\n",
    "!pip install causal-conv1d && pip install mamba-ssm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GrsQZ-KyoqWW"
   },
   "outputs": [],
   "source": [
    "# !pip uninstall torch\n",
    "# !pip install torch --index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ozvbuj_15knF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from mamba_ssm import Mamba  # Assuming Mamba is installed\n",
    "import math\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TWn5NXaA4PQ-"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "O3Tm30CZylSa"
   },
   "outputs": [],
   "source": [
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = pe.unsqueeze(0).to(device)  # Shape: (1, max_len, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :]  # Add positional encoding\n",
    "\n",
    "\n",
    "class MambaAttentionClassifier(nn.Module):\n",
    "    def __init__(self, ts_feature_dim, static_feature_dim, hidden_dim, num_classes):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            ts_feature_dim (int): Number of features in time-series data (e.g., 37).\n",
    "            static_feature_dim (int): Number of features in static data (e.g., 8).\n",
    "            hidden_dim (int): Dimension of hidden states in the model.\n",
    "            num_classes (int): Number of output classes (e.g., 2 for binary classification).\n",
    "        \"\"\"\n",
    "        super(MambaAttentionClassifier, self).__init__()\n",
    "\n",
    "        # Time-series processing with Mamba\n",
    "        self.positional_encoding = PositionalEncoding(d_model=ts_feature_dim)\n",
    "        self.mamba_layer = Mamba(\n",
    "            d_model=ts_feature_dim,  # Include time as an additional feature\n",
    "            d_state=hidden_dim,         # Mamba's internal state size\n",
    "            d_conv=4,                   # Convolution width for local dependencies\n",
    "            expand=2                    # Expansion factor\n",
    "        )\n",
    "\n",
    "        self.projection = nn.Linear(ts_feature_dim, hidden_dim)\n",
    "        self.mamba_norm = nn.LayerNorm(hidden_dim)  # Layer normalization for stability\n",
    "\n",
    "\n",
    "        # Multi-head attention\n",
    "        self.multihead_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=4, batch_first=True)\n",
    "\n",
    "        # Static feature processing\n",
    "        self.static_fc = nn.Linear(static_feature_dim, hidden_dim)\n",
    "        self.static_norm = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        # Fully connected layers for classification\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, ts_values, ts_indicators, ts_time, static):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            ts_values (torch.Tensor): Time-series data (batch_size, seq_len, ts_feature_dim).\n",
    "            ts_indicators (torch.Tensor): Indicator for missing time-series data (batch_size, seq_len, ts_feature_dim).\n",
    "            ts_time (torch.Tensor): Time-series timestamps (batch_size, seq_len).\n",
    "            static (torch.Tensor): Static features (batch_size, static_feature_dim).\n",
    "        Returns:\n",
    "            torch.Tensor: Class probabilities (batch_size, num_classes).\n",
    "        \"\"\"\n",
    "        # Ensure the shape of ts_indicators matches ts_values\n",
    "        assert ts_values.shape == ts_indicators.shape, \"Shape mismatch between ts_values and ts_indicators\"\n",
    "\n",
    "        # Handle missing data: Mask out the missing time-series values using ts_indicators\n",
    "        ts_values = ts_values * ts_indicators  # Element-wise multiplication to mask missing data\n",
    "\n",
    "        # Add time as an additional feature and apply positional encoding\n",
    "        ts_time = ts_time.unsqueeze(-1)  # (batch_size, seq_len, 1)\n",
    "        ts_combined = torch.cat([ts_values, ts_time], dim=-1)  # (batch_size, seq_len, ts_feature_dim + 1)\n",
    "        ts_combined = self.positional_encoding(ts_combined)\n",
    "\n",
    "        # Process time-series data with Mamba\n",
    "        ts_encoded = self.mamba_layer(ts_combined)  # (batch_size, seq_len, hidden_dim)\n",
    "        ts_encoded = self.projection(ts_encoded)  # (batch_size, seq_len, hidden_dim)\n",
    "        ts_encoded = self.mamba_norm(ts_encoded)  # Normalize the Mamba output\n",
    "\n",
    "\n",
    "        # Apply multi-head attention\n",
    "        ts_encoded, _ = self.multihead_attention(ts_encoded, ts_encoded, ts_encoded)\n",
    "\n",
    "        # Compute attention weights\n",
    "        attn_weights = F.softmax(torch.mean(ts_encoded, dim=-1, keepdim=True), dim=1)  # (batch_size, seq_len, 1)\n",
    "        ts_attended = torch.sum(attn_weights * ts_encoded, dim=1)  # (batch_size, hidden_dim)\n",
    "\n",
    "        # Process static features\n",
    "        static_encoded = F.relu(self.static_fc(static))  # (batch_size, hidden_dim)\n",
    "        static_encoded = self.static_norm(static_encoded)\n",
    "\n",
    "        # Concatenate attended time-series and static features\n",
    "        combined = torch.cat([ts_attended, static_encoded], dim=1)  # (batch_size, hidden_dim * 2)\n",
    "\n",
    "        # Classification\n",
    "        output = self.classifier(combined)  # (batch_size, num_classes)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "UIG39zTTtHxv"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MambaAttentionClassifier(nn.Module):\n",
    "    def __init__(self, ts_feature_dim, static_feature_dim, hidden_dim, num_classes):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            ts_feature_dim (int): Number of features in time-series data (e.g., 37).\n",
    "            static_feature_dim (int): Number of features in static data (e.g., 8).\n",
    "            hidden_dim (int): Dimension of hidden states in the model.\n",
    "            num_classes (int): Number of output classes (e.g., 2 for binary classification).\n",
    "        \"\"\"\n",
    "        super(MambaAttentionClassifier, self).__init__()\n",
    "\n",
    "        # Time-series processing with Mamba\n",
    "        self.mamba_layer = Mamba(\n",
    "            d_model=ts_feature_dim,  # Include time as an additional feature\n",
    "            d_state=hidden_dim,         # Mamba's internal state size\n",
    "            d_conv=4,                   # Convolution width for local dependencies\n",
    "            expand=2                    # Expansion factor\n",
    "        )\n",
    "\n",
    "        # Static feature processing\n",
    "        self.static_fc = nn.Linear(static_feature_dim, hidden_dim)\n",
    "\n",
    "        # Attention layer to weight time-series features\n",
    "        self.attention = nn.Linear(ts_feature_dim, 1)\n",
    "\n",
    "        # Fully connected layers for classification\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(ts_feature_dim + hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, ts_values, ts_indicators, ts_time, static):\n",
    "      \"\"\"\n",
    "      Args:\n",
    "          ts_values (torch.Tensor): Time-series data (batch_size, seq_len, ts_feature_dim).\n",
    "          ts_indicators (torch.Tensor): Indicator for missing time-series data (batch_size, seq_len, ts_feature_dim).\n",
    "          ts_time (torch.Tensor): Time-series timestamps (batch_size, seq_len).\n",
    "          static (torch.Tensor): Static features (batch_size, static_feature_dim).\n",
    "      Returns:\n",
    "          torch.Tensor: Class probabilities (batch_size, num_classes).\n",
    "      \"\"\"\n",
    "      # Ensure the shape of ts_indicators matches ts_values\n",
    "      assert ts_values.shape == ts_indicators.shape, \"Shape mismatch between ts_values and ts_indicators\"\n",
    "\n",
    "      # Handle missing data: Mask out the missing time-series values using ts_indicators\n",
    "      ts_values = ts_values * ts_indicators  # Element-wise multiplication to mask missing data\n",
    "\n",
    "      ts_time = ts_time.unsqueeze(-1)  # (batch_size, seq_len, 1)\n",
    "      ts_combined = torch.cat([ts_values, ts_time], dim=-1)  # (batch_size, seq_len, ts_feature_dim + 1)\n",
    "\n",
    "      # Process time-series data with Mamba\n",
    "      ts_encoded = self.mamba_layer(ts_combined)  # (batch_size, seq_len, hidden_dim)\n",
    "\n",
    "      # print('ts_encoded shape',ts_encoded.shape)\n",
    "\n",
    "      # Reshape ts_encoded for the attention layer\n",
    "      batch_size, seq_len, hidden_dim = ts_encoded.shape\n",
    "      ts_encoded_flat = ts_encoded.view(-1, hidden_dim)  # Flatten to (batch_size * seq_len, hidden_dim)\n",
    "\n",
    "      # Compute attention scores\n",
    "      attn_scores = self.attention(ts_encoded_flat)  # (batch_size * seq_len, 1)\n",
    "      attn_scores = attn_scores.view(batch_size, seq_len, 1)  # Reshape back to (batch_size, seq_len, 1)\n",
    "\n",
    "      # Compute attention weights\n",
    "      attn_weights = F.softmax(attn_scores, dim=1)  # (batch_size, seq_len, 1)\n",
    "\n",
    "      # Apply attention weights to the Mamba output\n",
    "      ts_attended = torch.sum(attn_weights * ts_encoded, dim=1)  # (batch_size, hidden_dim)\n",
    "\n",
    "      # Process static features\n",
    "      static_encoded = F.relu(self.static_fc(static))  # (batch_size, hidden_dim)\n",
    "\n",
    "      # Concatenate attended time-series and static features\n",
    "      combined = torch.cat([ts_attended, static_encoded], dim=1)  # (batch_size, hidden_dim * 2)\n",
    "\n",
    "      # print('ts_attended shape',ts_attended.shape)\n",
    "      # print('static_encoded shape', static_encoded.shape)\n",
    "      # print('combined shape', combined.shape)\n",
    "\n",
    "      # Classification\n",
    "      output = self.classifier(combined)  # (batch_size, num_classes)\n",
    "\n",
    "      return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zU1JAElcyRRp"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        # Compute sine and cosine values separately\n",
    "        pe[:, 0::2] = torch.sin(position * div_term[: (d_model + 1) // 2])  # Handle odd d_model for sine\n",
    "        pe[:, 1::2] = torch.cos(position * div_term[: d_model // 2])  # Handle odd d_model for cosine\n",
    "\n",
    "        self.pe = pe.unsqueeze(0).to(device)  # Shape: (1, max_len, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :]  # Add positional encoding\n",
    "\n",
    "\n",
    "class MambaAttentionClassifier(nn.Module):\n",
    "    def __init__(self, ts_feature_dim, static_feature_dim, hidden_dim, num_classes, max_time_steps=1000):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            ts_feature_dim (int): Number of features in time-series data (e.g., 37).\n",
    "            static_feature_dim (int): Number of features in static data (e.g., 8).\n",
    "            hidden_dim (int): Dimension of hidden states in the model.\n",
    "            num_classes (int): Number of output classes (e.g., 2 for binary classification).\n",
    "            max_time_steps (int): Maximum number of time steps for time embedding.\n",
    "        \"\"\"\n",
    "        super(MambaAttentionClassifier, self).__init__()\n",
    "\n",
    "        # Time-series positional encoding\n",
    "        self.positional_encoding = PositionalEncoding(d_model=ts_feature_dim)\n",
    "\n",
    "        # Time embedding for dynamic time features\n",
    "        self.time_embedding = nn.Embedding(max_time_steps, ts_feature_dim)\n",
    "\n",
    "\n",
    "        # Mamba layer with residual connection\n",
    "        self.mamba_layer = Mamba(\n",
    "            d_model=ts_feature_dim,  # Input feature dimension\n",
    "            d_state=hidden_dim,      # Mamba's hidden state size\n",
    "            d_conv=4,                # Convolution width\n",
    "            expand=2                 # Expansion factor\n",
    "        )\n",
    "        self.projection = nn.Linear(ts_feature_dim, hidden_dim)\n",
    "        self.mamba_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.mamba_dropout = nn.Dropout(0.3)\n",
    "\n",
    "        # Multi-head attention with residual connection\n",
    "        self.multihead_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=4, dropout=0.2, batch_first=True)\n",
    "\n",
    "        # Learnable attention mechanism\n",
    "        self.attention_layer = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        # Static feature encoder\n",
    "        self.static_fc = nn.utils.weight_norm(nn.Linear(static_feature_dim, hidden_dim))\n",
    "        self.static_norm = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        # Fully connected classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, ts_values, ts_indicators, ts_time, static):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            ts_values (torch.Tensor): Time-series data (batch_size, seq_len, ts_feature_dim).\n",
    "            ts_indicators (torch.Tensor): Indicator for missing time-series data (batch_size, seq_len, ts_feature_dim).\n",
    "            ts_time (torch.Tensor): Time-series timestamps (batch_size, seq_len).\n",
    "            static (torch.Tensor): Static features (batch_size, static_feature_dim).\n",
    "        Returns:\n",
    "            torch.Tensor: Class probabilities (batch_size, num_classes).\n",
    "        \"\"\"\n",
    "        # Ensure the shape of ts_indicators matches ts_values\n",
    "        assert ts_values.shape == ts_indicators.shape, \"Shape mismatch between ts_values and ts_indicators\"\n",
    "\n",
    "        # Mask missing time-series values\n",
    "        ts_values = ts_values * ts_indicators\n",
    "\n",
    "        # Add positional encoding and time embedding\n",
    "        ts_time_embed = self.time_embedding(ts_time.long())  # (batch_size, seq_len, ts_feature_dim)\n",
    "        ts_combined = ts_values + ts_time_embed  # Element-wise addition\n",
    "        ts_combined = self.positional_encoding(ts_combined)\n",
    "\n",
    "        # Process time-series data with Mamba\n",
    "        ts_encoded = self.mamba_layer(ts_combined)  # (batch_size, seq_len, hidden_dim)\n",
    "\n",
    "        ts_encoded = self.projection(ts_encoded)  # (batch_size, seq_len, hidden_dim)\n",
    "\n",
    "        ts_encoded = self.mamba_norm(ts_encoded)  # Normalize Mamba output\n",
    "        ts_encoded = self.mamba_dropout(ts_encoded)  # Apply dropout\n",
    "\n",
    "        # Apply multi-head attention with residual connection\n",
    "        attn_output, _ = self.multihead_attention(ts_encoded, ts_encoded, ts_encoded)\n",
    "        ts_encoded = ts_encoded + attn_output  # Residual connection\n",
    "\n",
    "        # Compute learnable attention weights\n",
    "        attn_scores = self.attention_layer(ts_encoded).squeeze(-1)  # (batch_size, seq_len)\n",
    "        attn_weights = F.softmax(attn_scores, dim=1)  # (batch_size, seq_len)\n",
    "        ts_attended = torch.sum(ts_encoded * attn_weights.unsqueeze(-1), dim=1)  # (batch_size, hidden_dim)\n",
    "\n",
    "        # Process static features\n",
    "        static_encoded = F.relu(self.static_fc(static))  # (batch_size, hidden_dim)\n",
    "        static_encoded = self.static_norm(static_encoded)\n",
    "\n",
    "        # Concatenate time-series and static features\n",
    "        combined = torch.cat([ts_attended, static_encoded], dim=1)  # (batch_size, hidden_dim * 2)\n",
    "\n",
    "        # Classification\n",
    "        output = self.classifier(combined)  # (batch_size, num_classes)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_mkx_nPa1nqi"
   },
   "outputs": [],
   "source": [
    "# FINAL MODEL OF MULTIHEAD ATTENTION WITH MAMBA\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        # Compute sine and cosine values separately\n",
    "        pe[:, 0::2] = torch.sin(position * div_term[: (d_model + 1) // 2])  # Handle odd d_model for sine\n",
    "        pe[:, 1::2] = torch.cos(position * div_term[: d_model // 2])  # Handle odd d_model for cosine\n",
    "\n",
    "        self.pe = pe.unsqueeze(0).to(device)  # Shape: (1, max_len, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :]  # Add positional encoding\n",
    "\n",
    "class MambaAttentionClassifier(nn.Module):\n",
    "    def __init__(self, ts_feature_dim, static_feature_dim, hidden_dim, num_classes, max_time_steps=1000):\n",
    "        super(MambaAttentionClassifier, self).__init__()\n",
    "\n",
    "        # Time-series positional encoding\n",
    "        self.positional_encoding = PositionalEncoding(d_model=ts_feature_dim)\n",
    "\n",
    "        # Time embedding for dynamic time features\n",
    "        self.time_embedding = nn.Embedding(max_time_steps, ts_feature_dim)\n",
    "\n",
    "        # First Mamba layer with residual connection\n",
    "        self.mamba_layer1 = Mamba(\n",
    "            d_model=ts_feature_dim,  # Input feature dimension\n",
    "            d_state=hidden_dim,      # Mamba's hidden state size\n",
    "            d_conv=4,                # Convolution width\n",
    "            expand=2                 # Expansion factor\n",
    "        )\n",
    "\n",
    "        # Second Mamba layer\n",
    "        self.mamba_layer2 = Mamba(\n",
    "            d_model=hidden_dim,      # Output of first Mamba layer\n",
    "            d_state=hidden_dim,      # Mamba's hidden state size\n",
    "            d_conv=4,\n",
    "            expand=2\n",
    "        )\n",
    "\n",
    "        self.projection = nn.Linear(ts_feature_dim, hidden_dim)\n",
    "        self.mamba_norm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.mamba_norm2 = nn.LayerNorm(hidden_dim)\n",
    "        self.mamba_dropout = nn.Dropout(0.3)\n",
    "\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "        # Multi-head attention with residual connection\n",
    "        self.multihead_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=4, dropout=0.2, batch_first=True)\n",
    "\n",
    "        # Learnable attention mechanism\n",
    "        self.attention_layer = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        # Static feature encoder\n",
    "        self.static_fc = nn.utils.weight_norm(nn.Linear(static_feature_dim, hidden_dim))\n",
    "        self.static_norm = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        # Fully connected classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, ts_values, ts_indicators, ts_time, static):\n",
    "        # Ensure the shape of ts_indicators matches ts_values\n",
    "        assert ts_values.shape == ts_indicators.shape, \"Shape mismatch between ts_values and ts_indicators\"\n",
    "\n",
    "        # Mask missing time-series values\n",
    "        ts_values = ts_values * ts_indicators\n",
    "\n",
    "        # Add positional encoding and time embedding\n",
    "        ts_time_embed = self.time_embedding(ts_time.long())  # (batch_size, seq_len, ts_feature_dim)\n",
    "        ts_combined = ts_values + ts_time_embed  # Element-wise addition\n",
    "        ts_combined = self.positional_encoding(ts_combined)\n",
    "\n",
    "        # Process time-series data with the first Mamba layer\n",
    "        ts_encoded = self.mamba_layer1(ts_combined)  # (batch_size, seq_len, hidden_dim)\n",
    "        ts_encoded = self.projection(ts_encoded)  # (batch_size, seq_len, hidden_dim)\n",
    "        ts_encoded = self.mamba_norm1(ts_encoded)  # Normalize Mamba output\n",
    "        ts_encoded = self.mamba_dropout(ts_encoded)  # Apply dropout\n",
    "\n",
    "        # Process with the second Mamba layer\n",
    "        ts_encoded = self.mamba_layer2(ts_encoded)  # (batch_size, seq_len, hidden_dim)\n",
    "        ts_encoded = self.mamba_norm2(ts_encoded)  # Normalize second Mamba output\n",
    "        ts_encoded = self.mamba_dropout(ts_encoded)  # Apply dropout again\n",
    "\n",
    "        ts_encoded = self.batch_norm(ts_encoded.transpose(1, 2)).transpose(1, 2)\n",
    "\n",
    "        # Apply multi-head attention with residual connection\n",
    "        attn_output, _ = self.multihead_attention(ts_encoded, ts_encoded, ts_encoded)\n",
    "        ts_encoded = ts_encoded + attn_output  # Residual connection\n",
    "\n",
    "        # Compute learnable attention weights\n",
    "        attn_scores = self.attention_layer(ts_encoded).squeeze(-1)  # (batch_size, seq_len)\n",
    "        attn_weights = F.softmax(attn_scores, dim=1)  # (batch_size, seq_len)\n",
    "        ts_attended = torch.sum(ts_encoded * attn_weights.unsqueeze(-1), dim=1)  # (batch_size, hidden_dim)\n",
    "\n",
    "        # Process static features\n",
    "        static_encoded = F.relu(self.static_fc(static))  # (batch_size, hidden_dim)\n",
    "        static_encoded = self.static_norm(static_encoded)\n",
    "\n",
    "        # Concatenate attended time-series and static features\n",
    "        combined = torch.cat([ts_attended, static_encoded], dim=1)  # (batch_size, hidden_dim * 2)\n",
    "\n",
    "        # Classification\n",
    "        output = self.classifier(combined)  # (batch_size, num_classes)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "yEG3SaOfwvan"
   },
   "outputs": [],
   "source": [
    "class EnhancedMambaAttentionClassifier(nn.Module):\n",
    "    def __init__(self, ts_feature_dim, static_feature_dim, hidden_dim, num_classes, max_time_steps=1000):\n",
    "        super(EnhancedMambaAttentionClassifier, self).__init__()\n",
    "\n",
    "        # Time-series positional encoding\n",
    "        self.positional_encoding = PositionalEncoding(d_model=ts_feature_dim)\n",
    "\n",
    "        # Time embedding for dynamic time features\n",
    "        self.time_embedding = nn.Embedding(max_time_steps, ts_feature_dim)\n",
    "\n",
    "        # First Mamba layer\n",
    "        self.mamba_layer1 = Mamba(\n",
    "            d_model=ts_feature_dim,\n",
    "            d_state=hidden_dim,\n",
    "            d_conv=4,  # Wider convolution for better receptive fields\n",
    "            expand=2\n",
    "        )\n",
    "\n",
    "        # Second Mamba layer\n",
    "        self.mamba_layer2 = Mamba(\n",
    "            d_model=hidden_dim,\n",
    "            d_state=hidden_dim,\n",
    "            d_conv=4,\n",
    "            expand=4  # Increase expansion factor for more non-linear capacity\n",
    "        )\n",
    "\n",
    "        # Multi-head attention with residual connection\n",
    "        self.multihead_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=8, dropout=0.2, batch_first=True)\n",
    "\n",
    "        # Learnable attention mechanism\n",
    "        self.attention_layer = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        # Static feature encoder\n",
    "        self.static_fc = nn.Sequential(\n",
    "            nn.utils.weight_norm(nn.Linear(static_feature_dim, hidden_dim)),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "\n",
    "        # Fully connected classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.GELU(),  # Replace ReLU with GELU for smoother gradients\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "\n",
    "        # Additional layers and normalization\n",
    "        self.projection = nn.Linear(ts_feature_dim, hidden_dim)\n",
    "        self.mamba_norm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.mamba_norm2 = nn.LayerNorm(hidden_dim)\n",
    "        self.mamba_dropout = nn.Dropout(0.3)\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "    def forward(self, ts_values, ts_indicators, ts_time, static):\n",
    "        # Ensure the shape of ts_indicators matches ts_values\n",
    "        assert ts_values.shape == ts_indicators.shape, \"Shape mismatch between ts_values and ts_indicators\"\n",
    "\n",
    "        # Mask missing time-series values\n",
    "        ts_values = ts_values * ts_indicators\n",
    "\n",
    "        # Add positional encoding and time embedding\n",
    "        ts_time_embed = self.time_embedding(ts_time.long())\n",
    "        ts_combined = ts_values + ts_time_embed\n",
    "        ts_combined = self.positional_encoding(ts_combined)\n",
    "\n",
    "        # Process time-series data with Mamba layers\n",
    "        ts_encoded = self.mamba_layer1(ts_combined)\n",
    "        ts_encoded = self.projection(ts_encoded)\n",
    "        ts_encoded = self.mamba_norm1(ts_encoded)\n",
    "        ts_encoded = self.mamba_dropout(ts_encoded)\n",
    "\n",
    "        ts_encoded = self.mamba_layer2(ts_encoded)\n",
    "        ts_encoded = self.mamba_norm2(ts_encoded)\n",
    "        ts_encoded = self.mamba_dropout(ts_encoded)\n",
    "\n",
    "        # Batch normalization for stability\n",
    "        ts_encoded = self.batch_norm(ts_encoded.transpose(1, 2)).transpose(1, 2)\n",
    "\n",
    "        # Multi-head attention with residual connection\n",
    "        attn_output, _ = self.multihead_attention(ts_encoded, ts_encoded, ts_encoded)\n",
    "        ts_encoded = ts_encoded + attn_output\n",
    "\n",
    "        # Compute learnable attention weights\n",
    "        attn_scores = self.attention_layer(ts_encoded).squeeze(-1)\n",
    "        attn_weights = F.softmax(attn_scores, dim=1)\n",
    "        ts_attended = torch.sum(ts_encoded * attn_weights.unsqueeze(-1), dim=1)\n",
    "\n",
    "        # Process static features\n",
    "        static_encoded = self.static_fc(static)\n",
    "\n",
    "        # Concatenate attended time-series and static features\n",
    "        combined = torch.cat([ts_attended, static_encoded], dim=1)\n",
    "\n",
    "        # Classification\n",
    "        output = self.classifier(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "j3VThDmaueHt"
   },
   "outputs": [],
   "source": [
    "class MoEMambaAttentionClassifier(nn.Module):\n",
    "    def __init__(self, ts_feature_dim, static_feature_dim, hidden_dim, num_classes, num_experts=4, max_time_steps=1000):\n",
    "        super(MoEMambaAttentionClassifier, self).__init__()\n",
    "\n",
    "        self.num_experts = num_experts\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Gating network\n",
    "        self.gating_network = nn.Sequential(\n",
    "            nn.Linear(ts_feature_dim, num_experts),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "        # Input projection to match hidden_dim\n",
    "        self.input_projection = nn.Linear(ts_feature_dim, hidden_dim)\n",
    "\n",
    "        # Define experts (using Mamba layers here)\n",
    "        self.experts = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                Mamba(d_model=hidden_dim, d_state=hidden_dim, d_conv=4, expand=2),\n",
    "                nn.LayerNorm(hidden_dim),\n",
    "                nn.Dropout(0.3)\n",
    "            )\n",
    "            for _ in range(num_experts)\n",
    "        ])\n",
    "\n",
    "        # Remaining layers (similar to your current model)\n",
    "        self.projection = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.multihead_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=4, dropout=0.2, batch_first=True)\n",
    "        self.attention_layer = nn.Linear(hidden_dim, 1)\n",
    "        self.static_fc = nn.utils.weight_norm(nn.Linear(static_feature_dim, hidden_dim))\n",
    "        self.static_norm = nn.LayerNorm(hidden_dim)\n",
    "        # self.classifier = nn.Sequential(\n",
    "        #     nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(0.5),\n",
    "        #     nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(hidden_dim // 2, num_classes)\n",
    "        # )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, 1),  # Single output for binary classification\n",
    "            nn.Sigmoid()                   # Sigmoid activation for probabilities\n",
    "        )\n",
    "\n",
    "    def forward(self, ts_values, ts_indicators, ts_time, static):\n",
    "      # Mask missing time-series values\n",
    "      ts_values = ts_values * ts_indicators\n",
    "\n",
    "      # Compute gating scores using the original ts_values (before projection)\n",
    "      gating_scores = self.gating_network(ts_values.mean(dim=1))  # Shape: (batch_size, num_experts)\n",
    "      gating_weights = F.softmax(gating_scores, dim=-1)  # Shape: (batch_size, num_experts)\n",
    "\n",
    "      # Project input to match hidden_dim for experts\n",
    "      ts_values_projected = self.input_projection(ts_values)  # Shape: (batch_size, seq_len, hidden_dim)\n",
    "\n",
    "      # Expert outputs\n",
    "      expert_outputs = []\n",
    "      for i, expert in enumerate(self.experts):\n",
    "          expert_output = expert(ts_values_projected)  # Shape: (batch_size, seq_len, hidden_dim)\n",
    "          expert_outputs.append(expert_output)\n",
    "      expert_outputs = torch.stack(expert_outputs, dim=1)  # Shape: (batch_size, num_experts, seq_len, hidden_dim)\n",
    "\n",
    "      # Combine expert outputs using gating weights\n",
    "      ts_encoded = torch.einsum('be,besh->bsh', gating_weights, expert_outputs)  # Weighted sum\n",
    "\n",
    "      # Multi-head attention\n",
    "      attn_output, _ = self.multihead_attention(ts_encoded, ts_encoded, ts_encoded)\n",
    "      ts_encoded = ts_encoded + attn_output  # Residual connection\n",
    "\n",
    "      # Compute learnable attention weights\n",
    "      attn_scores = self.attention_layer(ts_encoded).squeeze(-1)\n",
    "      attn_weights = F.softmax(attn_scores, dim=1)\n",
    "      ts_attended = torch.sum(ts_encoded * attn_weights.unsqueeze(-1), dim=1)\n",
    "\n",
    "      # Static features\n",
    "      static_encoded = F.relu(self.static_fc(static))\n",
    "      static_encoded = self.static_norm(static_encoded)\n",
    "\n",
    "      # Concatenate features\n",
    "      combined = torch.cat([ts_attended, static_encoded], dim=1)\n",
    "\n",
    "      # Classification\n",
    "      output = self.classifier(combined)\n",
    "      return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "pLsOkNjqjX71"
   },
   "outputs": [],
   "source": [
    "# # FINAL MOE MAMBA ATTENTION\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    PositionalEncoding is a PyTorch module that generates sinusoidal positional encodings\n",
    "    to be added to input embeddings.\n",
    "\n",
    "    Attributes:\n",
    "        d_model (int): Dimensionality of the embedding space.\n",
    "        max_len (int): Maximum length of input sequences. Defaults to 5000.\n",
    "        pe (torch.Tensor): A tensor containing precomputed positional encodings.\n",
    "            Shape: (1, max_len, d_model).\n",
    "\n",
    "    Methods:\n",
    "        forward(x): Adds the positional encodings to the input tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        # Compute sine and cosine values separately\n",
    "        pe[:, 0::2] = torch.sin(position * div_term[: (d_model + 1) // 2])  # Handle odd d_model for sine\n",
    "        pe[:, 1::2] = torch.cos(position * div_term[: d_model // 2])  # Handle odd d_model for cosine\n",
    "\n",
    "        self.pe = pe.unsqueeze(0).to(device)  # Shape: (1, max_len, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :]  # Add positional encoding\n",
    "\n",
    "class MoEMambaAttentionClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    A mixture-of-experts model that combines time-series and static features\n",
    "    using Mamba layers, attention mechanisms, and a classifier for multi-class tasks.\n",
    "\n",
    "    Attributes:\n",
    "        ts_feature_dim (int): Dimensionality of the time-series features.\n",
    "        static_feature_dim (int): Dimensionality of the static features.\n",
    "        hidden_dim (int): Hidden layer size for the model.\n",
    "        num_classes (int): Number of output classes for classification.\n",
    "        num_experts (int): Number of expert networks used in the mixture model.\n",
    "        max_time_steps (int): Maximum number of time steps for input sequences.\n",
    "    \"\"\"\n",
    "    def __init__(self, ts_feature_dim, static_feature_dim, hidden_dim, num_classes, num_experts=4, max_time_steps=1000):\n",
    "        super(MoEMambaAttentionClassifier, self).__init__()\n",
    "\n",
    "        self.num_experts = num_experts\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Time-series positional encoding\n",
    "        self.positional_encoding = PositionalEncoding(d_model=ts_feature_dim)\n",
    "\n",
    "        # Time embedding for dynamic time features\n",
    "        self.time_embedding = nn.Embedding(max_time_steps, ts_feature_dim)\n",
    "\n",
    "        # Gating network\n",
    "        self.gating_network = nn.Sequential(\n",
    "            nn.Linear(ts_feature_dim, num_experts),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "        # Input projection to match hidden_dim\n",
    "        self.input_projection = nn.Linear(ts_feature_dim, hidden_dim)\n",
    "\n",
    "        # Define experts (using Mamba layers here)\n",
    "        self.experts = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                Mamba(d_model=hidden_dim, d_state=hidden_dim, d_conv=4, expand=2),\n",
    "                nn.LayerNorm(hidden_dim),\n",
    "                nn.Dropout(0.3)\n",
    "            )\n",
    "            for _ in range(num_experts)\n",
    "        ])\n",
    "\n",
    "        # Remaining layers (similar to your current model)\n",
    "        self.projection = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.multihead_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=4, dropout=0.2, batch_first=True)\n",
    "        self.attention_layer = nn.Linear(hidden_dim, 1)\n",
    "        self.static_fc = nn.utils.weight_norm(nn.Linear(static_feature_dim, hidden_dim))\n",
    "        self.static_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, ts_values, ts_indicators, ts_time, static):\n",
    "      # Mask missing time-series values\n",
    "      ts_values = ts_values * ts_indicators\n",
    "\n",
    "\n",
    "      # Add positional encoding and time embedding\n",
    "      ts_time_embed = self.time_embedding(ts_time.long())\n",
    "      ts_combined = ts_values + ts_time_embed\n",
    "      ts_combined = self.positional_encoding(ts_combined)\n",
    "\n",
    "      # Compute gating scores using the original ts_values (before projection)\n",
    "      gating_scores = self.gating_network(ts_combined.mean(dim=1))  # Shape: (batch_size, num_experts)\n",
    "      gating_weights = F.softmax(gating_scores, dim=-1)  # Shape: (batch_size, num_experts)\n",
    "\n",
    "      # Project input to match hidden_dim for experts\n",
    "      ts_combined_projected = self.input_projection(ts_combined)  # Shape: (batch_size, seq_len, hidden_dim)\n",
    "\n",
    "      # Expert outputs\n",
    "      expert_outputs = []\n",
    "      for i, expert in enumerate(self.experts):\n",
    "          expert_output = expert(ts_combined_projected)  # Shape: (batch_size, seq_len, hidden_dim)\n",
    "          expert_outputs.append(expert_output)\n",
    "      expert_outputs = torch.stack(expert_outputs, dim=1)  # Shape: (batch_size, num_experts, seq_len, hidden_dim) - Ensembling\n",
    "\n",
    "      # Combine expert outputs using gating weights\n",
    "      ts_encoded = torch.einsum('be,besh->bsh', gating_weights, expert_outputs)  # Weighted sum\n",
    "\n",
    "      # Multi-head attention\n",
    "      attn_output, _ = self.multihead_attention(ts_encoded, ts_encoded, ts_encoded)\n",
    "      ts_encoded = ts_encoded + attn_output  # Residual connection\n",
    "\n",
    "      # Compute learnable attention weights\n",
    "      attn_scores = self.attention_layer(ts_encoded).squeeze(-1)\n",
    "      attn_weights = F.softmax(attn_scores, dim=1)\n",
    "      ts_attended = torch.sum(ts_encoded * attn_weights.unsqueeze(-1), dim=1)\n",
    "\n",
    "      # Static features\n",
    "      static_encoded = F.relu(self.static_fc(static))\n",
    "      static_encoded = self.static_norm(static_encoded)\n",
    "\n",
    "      # Concatenate features\n",
    "      combined = torch.cat([ts_attended, static_encoded], dim=1)\n",
    "\n",
    "      # Classification\n",
    "      output = self.classifier(combined)\n",
    "      return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "rIwaoK-Gy0fx"
   },
   "outputs": [],
   "source": [
    "# drive.mount('/content/drive')\n",
    "# project_dir = '/content/drive/My Drive/ssm_ehr'\n",
    "train_data = np.load('/content/drive/MyDrive/ssm_ehr/datasets/split_1/train_physionet2012_1.npy', allow_pickle=True)\n",
    "test_data = np.load('/content/drive/MyDrive/ssm_ehr/datasets/split_1/test_physionet2012_1.npy', allow_pickle=True)\n",
    "val_data = np.load('/content/drive/MyDrive/ssm_ehr/datasets/split_1/validation_physionet2012_1.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wsjLVeS-xTkG"
   },
   "outputs": [],
   "source": [
    "\n",
    "def custom_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to handle batches with variable-length time-series data and static features.\n",
    "\n",
    "    Args:\n",
    "        batch (list of tuples): Each tuple contains (ts_values, ts_indicators, ts_time, static, labels).\n",
    "\n",
    "    Returns:\n",
    "        tuple: Padded time-series values, indicators, times, static features, and labels.\n",
    "    \"\"\"\n",
    "    ts_values = [sample[0].clone().detach().float() for sample in batch]\n",
    "    ts_indicators = [sample[1].clone().detach().float() for sample in batch]\n",
    "    ts_times = [sample[2].clone().detach().float() for sample in batch]\n",
    "    static = torch.stack([sample[3].clone().detach().float() for sample in batch])\n",
    "    labels = torch.tensor([sample[4] for sample in batch], dtype=torch.float32)\n",
    "\n",
    "    # Pad ts_values, ts_indicators, and ts_time\n",
    "    ts_values_padded = pad_sequence(ts_values, batch_first=True)\n",
    "    ts_indicators_padded = pad_sequence(ts_indicators, batch_first=True)\n",
    "    ts_times_padded = pad_sequence(ts_times, batch_first=True)\n",
    "\n",
    "    return ts_values_padded, ts_indicators_padded, ts_times_padded, static, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3JIm0_MdxXIu"
   },
   "outputs": [],
   "source": [
    "\n",
    "class ICUTimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        return (\n",
    "            torch.tensor(sample['ts_values'], dtype=torch.float32),  # Time-series values\n",
    "            torch.tensor(sample['ts_indicators'], dtype=torch.float32),  # Missing indicators\n",
    "            torch.tensor(sample['ts_times'], dtype=torch.float32),  # Time steps\n",
    "            torch.tensor(sample['static'], dtype=torch.float32),  # Static features\n",
    "            torch.tensor(sample['labels'], dtype=torch.float32)  # Label\n",
    "        )\n",
    "\n",
    "\n",
    "train_dataset = ICUTimeSeriesDataset(train_data)\n",
    "val_dataset = ICUTimeSeriesDataset(val_data)\n",
    "test_dataset = ICUTimeSeriesDataset(test_data)\n",
    "\n",
    "# Dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uIOckuB_0ZBp",
    "outputId": "dc1b190c-0613-4433-cc5a-24d960163d72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3RW--6rwxYj_",
    "outputId": "7f1d5f71-1806-4673-b6ce-79a0404655f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 0.5149, Val Loss: 0.4410, AUC: 0.5653, AUPR: 0.2144, Accuracy: 0.8390\n",
      "Epoch [2/50], Train Loss: 0.4247, Val Loss: 0.4324, AUC: 0.6206, AUPR: 0.2496, Accuracy: 0.8390\n",
      "Epoch [3/50], Train Loss: 0.4097, Val Loss: 0.4228, AUC: 0.6754, AUPR: 0.2825, Accuracy: 0.8390\n",
      "Epoch [4/50], Train Loss: 0.3922, Val Loss: 0.4132, AUC: 0.7111, AUPR: 0.3089, Accuracy: 0.8390\n",
      "Epoch [5/50], Train Loss: 0.3842, Val Loss: 0.4015, AUC: 0.7254, AUPR: 0.3251, Accuracy: 0.8390\n",
      "Epoch [6/50], Train Loss: 0.3774, Val Loss: 0.4018, AUC: 0.7358, AUPR: 0.3357, Accuracy: 0.8390\n",
      "Epoch [7/50], Train Loss: 0.3667, Val Loss: 0.3994, AUC: 0.7448, AUPR: 0.3457, Accuracy: 0.8390\n",
      "Epoch [8/50], Train Loss: 0.3618, Val Loss: 0.3891, AUC: 0.7540, AUPR: 0.3652, Accuracy: 0.8390\n",
      "Epoch [9/50], Train Loss: 0.3560, Val Loss: 0.3857, AUC: 0.7618, AUPR: 0.3714, Accuracy: 0.8390\n",
      "Epoch [10/50], Train Loss: 0.3521, Val Loss: 0.3855, AUC: 0.7710, AUPR: 0.3793, Accuracy: 0.8390\n",
      "Epoch [11/50], Train Loss: 0.3505, Val Loss: 0.3848, AUC: 0.7750, AUPR: 0.3865, Accuracy: 0.8390\n",
      "Epoch [12/50], Train Loss: 0.3462, Val Loss: 0.3758, AUC: 0.7836, AUPR: 0.3980, Accuracy: 0.8390\n",
      "Epoch [13/50], Train Loss: 0.3412, Val Loss: 0.3701, AUC: 0.7888, AUPR: 0.4041, Accuracy: 0.8390\n",
      "Epoch [14/50], Train Loss: 0.3430, Val Loss: 0.3739, AUC: 0.7908, AUPR: 0.4072, Accuracy: 0.8390\n",
      "Epoch [15/50], Train Loss: 0.3371, Val Loss: 0.3791, AUC: 0.7943, AUPR: 0.4103, Accuracy: 0.8407\n",
      "Epoch [16/50], Train Loss: 0.3346, Val Loss: 0.3746, AUC: 0.7963, AUPR: 0.4136, Accuracy: 0.8407\n",
      "Epoch [17/50], Train Loss: 0.3331, Val Loss: 0.3645, AUC: 0.7982, AUPR: 0.4137, Accuracy: 0.8432\n",
      "Epoch [18/50], Train Loss: 0.3287, Val Loss: 0.3637, AUC: 0.7999, AUPR: 0.4178, Accuracy: 0.8424\n",
      "Epoch [19/50], Train Loss: 0.3293, Val Loss: 0.3671, AUC: 0.8019, AUPR: 0.4219, Accuracy: 0.8407\n",
      "Epoch [20/50], Train Loss: 0.3257, Val Loss: 0.3684, AUC: 0.8023, AUPR: 0.4229, Accuracy: 0.8424\n",
      "Epoch [21/50], Train Loss: 0.3283, Val Loss: 0.3600, AUC: 0.8046, AUPR: 0.4230, Accuracy: 0.8432\n",
      "Epoch [22/50], Train Loss: 0.3209, Val Loss: 0.3748, AUC: 0.8015, AUPR: 0.4205, Accuracy: 0.8415\n",
      "Epoch [23/50], Train Loss: 0.3209, Val Loss: 0.3652, AUC: 0.8063, AUPR: 0.4256, Accuracy: 0.8440\n",
      "Epoch [24/50], Train Loss: 0.3250, Val Loss: 0.3727, AUC: 0.8033, AUPR: 0.4225, Accuracy: 0.8449\n",
      "Epoch [25/50], Train Loss: 0.3204, Val Loss: 0.3697, AUC: 0.8052, AUPR: 0.4251, Accuracy: 0.8432\n",
      "Epoch [26/50], Train Loss: 0.3245, Val Loss: 0.3595, AUC: 0.8062, AUPR: 0.4234, Accuracy: 0.8432\n",
      "Epoch [27/50], Train Loss: 0.3218, Val Loss: 0.3680, AUC: 0.8042, AUPR: 0.4211, Accuracy: 0.8432\n",
      "Epoch [28/50], Train Loss: 0.3150, Val Loss: 0.3595, AUC: 0.8072, AUPR: 0.4256, Accuracy: 0.8432\n",
      "Epoch [29/50], Train Loss: 0.3150, Val Loss: 0.3711, AUC: 0.8070, AUPR: 0.4265, Accuracy: 0.8432\n",
      "Epoch [30/50], Train Loss: 0.3163, Val Loss: 0.3723, AUC: 0.8070, AUPR: 0.4248, Accuracy: 0.8424\n",
      "Epoch [31/50], Train Loss: 0.3120, Val Loss: 0.3639, AUC: 0.8093, AUPR: 0.4270, Accuracy: 0.8440\n",
      "Epoch [32/50], Train Loss: 0.3118, Val Loss: 0.3846, AUC: 0.8092, AUPR: 0.4267, Accuracy: 0.8407\n",
      "Epoch [33/50], Train Loss: 0.3131, Val Loss: 0.3669, AUC: 0.8085, AUPR: 0.4224, Accuracy: 0.8449\n",
      "Epoch [34/50], Train Loss: 0.3128, Val Loss: 0.3794, AUC: 0.8081, AUPR: 0.4253, Accuracy: 0.8407\n",
      "Epoch [35/50], Train Loss: 0.3095, Val Loss: 0.3803, AUC: 0.8091, AUPR: 0.4269, Accuracy: 0.8449\n",
      "Epoch [36/50], Train Loss: 0.3107, Val Loss: 0.3643, AUC: 0.8080, AUPR: 0.4259, Accuracy: 0.8382\n",
      "Epoch [37/50], Train Loss: 0.3077, Val Loss: 0.3643, AUC: 0.8094, AUPR: 0.4267, Accuracy: 0.8407\n",
      "Epoch [38/50], Train Loss: 0.3087, Val Loss: 0.3596, AUC: 0.8078, AUPR: 0.4224, Accuracy: 0.8415\n",
      "Epoch [39/50], Train Loss: 0.3064, Val Loss: 0.3623, AUC: 0.8074, AUPR: 0.4207, Accuracy: 0.8382\n",
      "Epoch [40/50], Train Loss: 0.3063, Val Loss: 0.3702, AUC: 0.8095, AUPR: 0.4273, Accuracy: 0.8349\n",
      "Epoch [41/50], Train Loss: 0.3071, Val Loss: 0.3773, AUC: 0.8094, AUPR: 0.4246, Accuracy: 0.8390\n",
      "Epoch [42/50], Train Loss: 0.3059, Val Loss: 0.3697, AUC: 0.8114, AUPR: 0.4280, Accuracy: 0.8407\n",
      "Epoch [43/50], Train Loss: 0.3055, Val Loss: 0.3589, AUC: 0.8111, AUPR: 0.4249, Accuracy: 0.8399\n",
      "Epoch [44/50], Train Loss: 0.3037, Val Loss: 0.3721, AUC: 0.8078, AUPR: 0.4230, Accuracy: 0.8390\n",
      "Epoch [45/50], Train Loss: 0.3045, Val Loss: 0.3727, AUC: 0.8085, AUPR: 0.4239, Accuracy: 0.8407\n",
      "Epoch [46/50], Train Loss: 0.3030, Val Loss: 0.3696, AUC: 0.8086, AUPR: 0.4226, Accuracy: 0.8399\n",
      "Epoch [47/50], Train Loss: 0.3015, Val Loss: 0.3677, AUC: 0.8055, AUPR: 0.4195, Accuracy: 0.8415\n",
      "Epoch [48/50], Train Loss: 0.2985, Val Loss: 0.3694, AUC: 0.8088, AUPR: 0.4249, Accuracy: 0.8399\n",
      "Epoch [49/50], Train Loss: 0.2994, Val Loss: 0.3817, AUC: 0.8060, AUPR: 0.4216, Accuracy: 0.8374\n",
      "Epoch [50/50], Train Loss: 0.2976, Val Loss: 0.3772, AUC: 0.8074, AUPR: 0.4192, Accuracy: 0.8415\n",
      "\n",
      "Test Loss: 0.3311, AUC: 0.8202, AUPR: 0.4473, Accuracy: 0.8624\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Define model\n",
    "\n",
    "model = MoEMambaAttentionClassifier(\n",
    "    ts_feature_dim=37,\n",
    "    static_feature_dim=8,\n",
    "    hidden_dim=16,\n",
    "    num_classes=2\n",
    ")\n",
    "\n",
    "def train(model, train_loader, val_loader, num_epochs = 100):\n",
    "  model.to(device)\n",
    "\n",
    "  # Loss and optimizer\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "  # Training loop\n",
    "  train_losses = []\n",
    "  val_losses = []\n",
    "  for epoch in range(num_epochs):  # Adjust epochs as needed\n",
    "      model.train()\n",
    "      loss_train = 0\n",
    "      for ts_values, ts_indicators, ts_time, static, labels in train_loader:\n",
    "          ts_values,ts_indicators, ts_time , static, labels = ts_values.to(device), ts_indicators.to(device), ts_time.to(device), static.to(device), labels.to(device)\n",
    "\n",
    "\n",
    "          # print(ts_values.shape)\n",
    "          # print(ts_indicators.shape)\n",
    "          # print(ts_time.shape)\n",
    "          # print(static.shape)\n",
    "          # print(labels.shape)\n",
    "          # break\n",
    "\n",
    "          # Forward pass\n",
    "          outputs = model(ts_values, ts_indicators, ts_time, static)\n",
    "          loss = criterion(outputs, labels.long())\n",
    "\n",
    "          # Backward pass\n",
    "          optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Clip gradients\n",
    "          optimizer.step()\n",
    "\n",
    "          loss_train += loss.item()\n",
    "\n",
    "      train_losses.append(loss_train/len(train_loader))\n",
    "\n",
    "      # validation loss\n",
    "      model.eval().to(device)\n",
    "      labels_list = torch.LongTensor([]).to(device)\n",
    "      predictions_list = torch.FloatTensor([]).to(device)\n",
    "      with torch.no_grad():\n",
    "          for ts_values, ts_indicators, ts_time, static, labels in val_loader:\n",
    "              ts_values,ts_indicators, ts_time, static, labels = ts_values.to(device), ts_indicators.to(device), ts_time.to(device), static.to(device), labels.to(device).long()\n",
    "              labels_list = torch.cat((labels_list, labels), dim=0)\n",
    "              predicition = model(ts_values, ts_indicators, ts_time, static)\n",
    "              predictions_list = torch.cat((predictions_list, predicition), dim=0)\n",
    "\n",
    "          probs = torch.nn.functional.softmax(predictions_list, dim=1)\n",
    "          auc_score = roc_auc_score(labels_list.cpu().numpy(), probs[:, 1].cpu().numpy())\n",
    "          aupr_score = average_precision_score(labels_list.cpu().numpy(), probs[:, 1].cpu().numpy())\n",
    "          accuracy = accuracy_score(labels_list.cpu().numpy(), (probs[:, 1] >= 0.5).cpu().numpy())\n",
    "\n",
    "      val_loss = criterion(predictions_list, labels_list)\n",
    "      val_losses.append(val_loss)\n",
    "      print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss_train/len(train_loader):.4f}, Val Loss: {val_loss:.4f}, AUC: {auc_score:.4f}, AUPR: {aupr_score:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "  return model, train_losses, val_losses\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval().to(device)  # Set model to evaluation mode\n",
    "\n",
    "    # Loss and metrics\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    test_losses = []\n",
    "    labels_list = torch.LongTensor([]).to(device)\n",
    "    predictions_list = torch.FloatTensor([]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loss_test = 0\n",
    "        for ts_values, ts_indicators, ts_time, static, labels in test_loader:\n",
    "            # Move data to device\n",
    "            ts_values, ts_indicators, ts_time, static, labels = (\n",
    "                ts_values.to(device),\n",
    "                ts_indicators.to(device),\n",
    "                ts_time.to(device),\n",
    "                static.to(device),\n",
    "                labels.to(device).long(),\n",
    "            )\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = model(ts_values, ts_indicators, ts_time, static)\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            # Accumulate test loss\n",
    "            loss_test += loss.item()\n",
    "\n",
    "            # Collect labels and predictions for metrics\n",
    "            labels_list = torch.cat((labels_list, labels), dim=0)\n",
    "            predictions_list = torch.cat((predictions_list, predictions), dim=0)\n",
    "\n",
    "        # Compute average test loss\n",
    "        test_losses.append(loss_test / len(test_loader))\n",
    "\n",
    "        # Compute probabilities for metrics\n",
    "        probs = torch.nn.functional.softmax(predictions_list, dim=1)\n",
    "        auc_score = roc_auc_score(labels_list.cpu().numpy(), probs[:, 1].cpu().numpy())\n",
    "        aupr_score = average_precision_score(labels_list.cpu().numpy(), probs[:, 1].cpu().numpy())\n",
    "        predicted_labels = (probs[:, 1] >= 0.5).cpu().numpy().astype(int)\n",
    "        accuracy = accuracy_score(labels_list.cpu().numpy(), predicted_labels)\n",
    "\n",
    "    # Print test results\n",
    "    print(f\"Test Loss: {test_losses[-1]:.4f}, AUC: {auc_score:.4f}, AUPR: {aupr_score:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    return test_losses, auc_score, aupr_score, accuracy\n",
    "\n",
    "model, train_losses, val_losses = train(model, train_loader, val_loader, 50)\n",
    "print()\n",
    "test_losses, auc_score, aupr_score, accuracy = test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "CyhIE_D96ACJ",
    "outputId": "2e15b6b0-23cc-4e44-91c5-58f6afbaa8f3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_losses(train_losses, validation_losses):\n",
    "    # Convert validation_losses to CPU and detach before plotting\n",
    "    validation_losses = [v.cpu().detach().numpy() for v in validation_losses]\n",
    "\n",
    "    # Set the figure size and style\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot training loss with markers\n",
    "    plt.plot(train_losses, label='Training Loss', color='tab:blue', marker='o', markersize=6, linestyle='-', linewidth=2)\n",
    "\n",
    "    # Plot validation loss with markers and different style\n",
    "    plt.plot(validation_losses, label='Validation Loss', color='tab:orange', marker='s', markersize=6, linestyle='--', linewidth=2)\n",
    "\n",
    "    # Add labels, title, and legend with improved styles\n",
    "    plt.xlabel('Epochs', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Loss', fontsize=14, fontweight='bold')\n",
    "    plt.title('Training and Validation Loss Over Epochs', fontsize=16, fontweight='bold')\n",
    "\n",
    "    # Display the legend with adjusted positioning\n",
    "    plt.legend(loc='upper right', fontsize=12)\n",
    "\n",
    "    # Adjust x and y ticks for better readability\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o6WTtyoNxZ2G",
    "outputId": "b6fa5217-5750-4890-fe37-9e60a4bc6e7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 84.15%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation loop\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for ts_values, ts_indicators, ts_time, static, labels in val_loader:\n",
    "        ts_values,ts_indicators,ts_time, static, labels = ts_values.to(device), ts_indicators.to(device),ts_time.to(device), static.to(device), labels.to(device)\n",
    "        outputs = model(ts_values, ts_indicators,ts_time, static)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.long()).sum().item()\n",
    "\n",
    "    print(f\"Validation Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "21P4H7sdxbFH"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the given data loader and calculates evaluation metrics.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Trained model.\n",
    "        data_loader (torch.utils.data.DataLoader): Data loader for validation/test set.\n",
    "        device (torch.device): Device to perform computation on (CPU/GPU).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing evaluation metrics.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_prob = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for ts_values, ts_indicators, ts_time, static, labels in data_loader:\n",
    "            # Move data to device\n",
    "            ts_values,ts_indicators, ts_time, static, labels = ts_values.to(device), ts_indicators.to(device), ts_time.to(device), static.to(device), labels.to(device)\n",
    "\n",
    "            # Get model predictions\n",
    "            outputs = model(ts_values, ts_indicators, ts_time, static)  # Raw logits\n",
    "            probabilities = torch.softmax(outputs, dim=1)[:, 1]  # Probability for class 1\n",
    "            predictions = torch.argmax(outputs, dim=1)  # Predicted class labels\n",
    "\n",
    "            # Collect predictions and ground truth\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predictions.cpu().numpy())\n",
    "            y_prob.extend(probabilities.cpu().numpy())\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=1)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=1)\n",
    "    roc_auc = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "    return {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-Score\": f1,\n",
    "        \"ROC-AUC\": roc_auc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xruKPV_1_d7N"
   },
   "source": [
    "Evaluate performance on all splits\n",
    "- Save data in the same format as baseline models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "R5OEqB8GIjGQ"
   },
   "outputs": [],
   "source": [
    "import time as time\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, num_epochs = 100):\n",
    "  model.to(device)\n",
    "\n",
    "  # Loss and optimizer\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "  # Training loop\n",
    "  train_losses = []\n",
    "  val_losses = []\n",
    "  AUC_scores = []\n",
    "  times = []\n",
    "\n",
    "  for epoch in range(num_epochs):  # Adjust epochs as needed\n",
    "      start_time = time.time()\n",
    "      model.train()\n",
    "      loss_train = 0\n",
    "      for ts_values, ts_indicators, ts_time, static, labels in train_loader:\n",
    "          ts_values,ts_indicators, ts_time , static, labels = ts_values.to(device), ts_indicators.to(device), ts_time.to(device), static.to(device), labels.to(device)\n",
    "\n",
    "          # Forward pass\n",
    "          outputs = model(ts_values, ts_indicators, ts_time, static)\n",
    "          loss = criterion(outputs, labels.long())\n",
    "\n",
    "          # Backward pass\n",
    "          optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Clip gradients\n",
    "          optimizer.step()\n",
    "\n",
    "          loss_train += loss.item()\n",
    "\n",
    "      train_losses.append(loss_train/len(train_loader))\n",
    "\n",
    "      # validation loss\n",
    "      model.eval().to(device)\n",
    "      labels_list = torch.LongTensor([]).to(device)\n",
    "      predictions_list = torch.FloatTensor([]).to(device)\n",
    "      with torch.no_grad():\n",
    "          for ts_values, ts_indicators, ts_time, static, labels in val_loader:\n",
    "              ts_values,ts_indicators, ts_time, static, labels = ts_values.to(device), ts_indicators.to(device), ts_time.to(device), static.to(device), labels.to(device).long()\n",
    "              labels_list = torch.cat((labels_list, labels), dim=0)\n",
    "              predicition = model(ts_values, ts_indicators, ts_time, static)\n",
    "              predictions_list = torch.cat((predictions_list, predicition), dim=0)\n",
    "\n",
    "          probs = torch.nn.functional.softmax(predictions_list, dim=1)\n",
    "          auc_score = roc_auc_score(labels_list.cpu().numpy(), probs[:, 1].cpu().numpy())\n",
    "          aupr_score = average_precision_score(labels_list.cpu().numpy(), probs[:, 1].cpu().numpy())\n",
    "          accuracy = accuracy_score(labels_list.cpu().numpy(), (probs[:, 1] >= 0.5).cpu().numpy())\n",
    "          AUC_scores.append(auc_score)\n",
    "\n",
    "      val_loss = criterion(predictions_list, labels_list)\n",
    "      val_losses.append(val_loss)\n",
    "      end_time = time.time()\n",
    "      delta = end_time-start_time\n",
    "      times.append(delta)\n",
    "\n",
    "      if epoch%20==0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss_train/len(train_loader):.4f}, Val Loss: {val_loss:.4f}, AUC: {auc_score:.4f}, AUPR: {aupr_score:.4f}, Accuracy: {accuracy:.4f}, Time: {delta}\")\n",
    "\n",
    "  return model, train_losses, val_losses, AUC_scores, times\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval().to(device)  # Set model to evaluation mode\n",
    "\n",
    "    # Loss and metrics\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    test_losses = []\n",
    "    labels_list = torch.LongTensor([]).to(device)\n",
    "    predictions_list = torch.FloatTensor([]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loss_test = 0\n",
    "        for ts_values, ts_indicators, ts_time, static, labels in test_loader:\n",
    "            # Move data to device\n",
    "            ts_values, ts_indicators, ts_time, static, labels = (\n",
    "                ts_values.to(device),\n",
    "                ts_indicators.to(device),\n",
    "                ts_time.to(device),\n",
    "                static.to(device),\n",
    "                labels.to(device).long(),\n",
    "            )\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = model(ts_values, ts_indicators, ts_time, static)\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            # Accumulate test loss\n",
    "            loss_test += loss.item()\n",
    "\n",
    "            # Collect labels and predictions for metrics\n",
    "            labels_list = torch.cat((labels_list, labels), dim=0)\n",
    "            predictions_list = torch.cat((predictions_list, predictions), dim=0)\n",
    "\n",
    "        # Compute average test loss\n",
    "        test_losses.append(loss_test / len(test_loader))\n",
    "\n",
    "        # Compute probabilities for metrics\n",
    "        probs = torch.nn.functional.softmax(predictions_list, dim=1)\n",
    "        auc_score = roc_auc_score(labels_list.cpu().numpy(), probs[:, 1].cpu().numpy())\n",
    "        aupr_score = average_precision_score(labels_list.cpu().numpy(), probs[:, 1].cpu().numpy())\n",
    "        predicted_labels = (probs[:, 1] >= 0.5).cpu().numpy().astype(int)\n",
    "        accuracy = accuracy_score(labels_list.cpu().numpy(), predicted_labels)\n",
    "\n",
    "    # Print test results\n",
    "    print(f\"Test Loss: {test_losses[-1]:.4f}, AUC: {auc_score:.4f}, AUPR: {aupr_score:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    return test_losses, auc_score, aupr_score, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "u8Z_uymw9s0x"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# empty dataframe for each split\n",
    "training_log = pd.DataFrame(columns=[\"epoch\",\t\"train_loss\",\t\"val_loss\",\t\"auc_score\", \"time\"])\n",
    "test_results = {\n",
    "    \"test_loss\": 0,\n",
    "    \"accuracy\": 0,\n",
    "    \"AUPRC\": 0,\n",
    "    \"AUROC\": 0,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "splits = range(1, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvc3Kp01Nir-"
   },
   "source": [
    "#### Loop over splits. Collect and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "AQ3eJsh2G1vM",
    "outputId": "7cb7e5c8-18fa-4dac-e1bf-5c00896af850"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.5299, Val Loss: 0.4397, AUC: 0.5560, AUPR: 0.1994, Accuracy: 0.8390, Time: 5.978167295455933\n",
      "Epoch [21/100], Train Loss: 0.3278, Val Loss: 0.3562, AUC: 0.8145, AUPR: 0.4510, Accuracy: 0.8432, Time: 5.840825080871582\n",
      "Epoch [41/100], Train Loss: 0.3066, Val Loss: 0.3584, AUC: 0.8242, AUPR: 0.4593, Accuracy: 0.8532, Time: 5.858995199203491\n",
      "Epoch [61/100], Train Loss: 0.2880, Val Loss: 0.3510, AUC: 0.8256, AUPR: 0.4711, Accuracy: 0.8524, Time: 5.783873081207275\n",
      "Epoch [81/100], Train Loss: 0.2737, Val Loss: 0.3760, AUC: 0.8178, AUPR: 0.4750, Accuracy: 0.8474, Time: 5.856794118881226\n",
      "Test Loss: 0.3251, AUC: 0.8225, AUPR: 0.4844, Accuracy: 0.8674\n",
      "Successfully saved data fromm split: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.6024, Val Loss: 0.4775, AUC: 0.6199, AUPR: 0.2352, Accuracy: 0.8449, Time: 6.095867872238159\n",
      "Epoch [21/100], Train Loss: 0.3352, Val Loss: 0.3364, AUC: 0.8232, AUPR: 0.5250, Accuracy: 0.8582, Time: 5.819227695465088\n",
      "Epoch [41/100], Train Loss: 0.3167, Val Loss: 0.3292, AUC: 0.8310, AUPR: 0.5290, Accuracy: 0.8641, Time: 5.90046238899231\n",
      "Epoch [61/100], Train Loss: 0.3013, Val Loss: 0.3244, AUC: 0.8364, AUPR: 0.5339, Accuracy: 0.8607, Time: 5.85589075088501\n",
      "Epoch [81/100], Train Loss: 0.2850, Val Loss: 0.3309, AUC: 0.8309, AUPR: 0.5063, Accuracy: 0.8682, Time: 5.879032611846924\n",
      "Test Loss: 0.3170, AUC: 0.8221, AUPR: 0.4378, Accuracy: 0.8716\n",
      "Successfully saved data fromm split: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.5050, Val Loss: 0.4525, AUC: 0.5009, AUPR: 0.1526, Accuracy: 0.8524, Time: 5.996852397918701\n",
      "Epoch [21/100], Train Loss: 0.3344, Val Loss: 0.3250, AUC: 0.8345, AUPR: 0.4749, Accuracy: 0.8557, Time: 5.6079277992248535\n",
      "Epoch [41/100], Train Loss: 0.3138, Val Loss: 0.3174, AUC: 0.8448, AUPR: 0.4923, Accuracy: 0.8657, Time: 5.915979385375977\n",
      "Epoch [61/100], Train Loss: 0.3013, Val Loss: 0.3207, AUC: 0.8404, AUPR: 0.4874, Accuracy: 0.8649, Time: 5.880053758621216\n",
      "Epoch [81/100], Train Loss: 0.2844, Val Loss: 0.3173, AUC: 0.8451, AUPR: 0.4931, Accuracy: 0.8666, Time: 5.877262115478516\n",
      "Test Loss: 0.3299, AUC: 0.8297, AUPR: 0.4736, Accuracy: 0.8607\n",
      "Successfully saved data fromm split: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.5208, Val Loss: 0.4056, AUC: 0.5838, AUPR: 0.1926, Accuracy: 0.8607, Time: 6.037936449050903\n",
      "Epoch [21/100], Train Loss: 0.3279, Val Loss: 0.3372, AUC: 0.7942, AUPR: 0.4260, Accuracy: 0.8607, Time: 5.746225118637085\n",
      "Epoch [41/100], Train Loss: 0.3082, Val Loss: 0.3297, AUC: 0.8032, AUPR: 0.4564, Accuracy: 0.8766, Time: 5.697206258773804\n",
      "Epoch [61/100], Train Loss: 0.2910, Val Loss: 0.3335, AUC: 0.8045, AUPR: 0.4421, Accuracy: 0.8716, Time: 5.905679225921631\n",
      "Epoch [81/100], Train Loss: 0.2770, Val Loss: 0.3322, AUC: 0.8040, AUPR: 0.4257, Accuracy: 0.8682, Time: 5.832646369934082\n",
      "Test Loss: 0.3520, AUC: 0.8112, AUPR: 0.4590, Accuracy: 0.8599\n",
      "Successfully saved data fromm split: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.8874, Val Loss: 0.6986, AUC: 0.6303, AUPR: 0.2099, Accuracy: 0.4270, Time: 5.793361186981201\n",
      "Epoch [21/100], Train Loss: 0.3429, Val Loss: 0.3131, AUC: 0.8298, AUPR: 0.4540, Accuracy: 0.8799, Time: 6.051904201507568\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-f06120e3077c>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;31m# Training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAUC_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0mtraining_log\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m101\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-f8f929bc44d2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, num_epochs)\u001b[0m\n\u001b[1;32m     30\u001b[0m           \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m           \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Clip gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m           \u001b[0mloss_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m                             )\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    224\u001b[0m             )\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    227\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    767\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    527\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_add_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m                 device_grads = torch._foreach_add(  # type: ignore[assignment]\n\u001b[0m\u001b[1;32m    530\u001b[0m                     \u001b[0mdevice_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m                 )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_path = project_dir + f\"/results/SMART_M_timed/\"\n",
    "\n",
    "for split in splits:\n",
    "\n",
    "  # Load data\n",
    "  train_data = np.load(f'/content/drive/MyDrive/ssm_ehr/datasets/split_{split}/train_physionet2012_{split}.npy', allow_pickle=True)\n",
    "  test_data = np.load(f'/content/drive/MyDrive/ssm_ehr/datasets/split_{split}/test_physionet2012_{split}.npy', allow_pickle=True)\n",
    "  val_data = np.load(f'/content/drive/MyDrive/ssm_ehr/datasets/split_{split}/validation_physionet2012_{split}.npy', allow_pickle=True)\n",
    "\n",
    "  train_dataset = ICUTimeSeriesDataset(train_data)\n",
    "  val_dataset = ICUTimeSeriesDataset(val_data)\n",
    "  test_dataset = ICUTimeSeriesDataset(test_data)\n",
    "\n",
    "  # Dataloader\n",
    "  train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=custom_collate_fn)\n",
    "  val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=custom_collate_fn)\n",
    "  test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "\n",
    "  # Reinstantiate a model after each split\n",
    "\n",
    "  model = MoEMambaAttentionClassifier(\n",
    "    ts_feature_dim=37,\n",
    "    static_feature_dim=8,\n",
    "    hidden_dim=16,\n",
    "    num_classes=2\n",
    "  )\n",
    "\n",
    "\n",
    "\n",
    "  # Training loop\n",
    "  model, train_losses, val_losses, AUC_scores, times = train(model, train_loader, val_loader, num_epochs = 100)\n",
    "\n",
    "  training_log[\"epoch\"]=[i for i in range(1, 101)]\n",
    "  # Convert CUDA tensors to numpy-compatible values\n",
    "  training_log[\"epoch\"] = [i for i in range(1, 101)]\n",
    "  training_log[\"train_loss\"] = [loss.cpu().item() if torch.is_tensor(loss) else loss for loss in train_losses]\n",
    "  training_log[\"val_loss\"] = [loss.cpu().item() if torch.is_tensor(loss) else loss for loss in val_losses]\n",
    "  training_log[\"auc_score\"] = [auc.cpu().item() if torch.is_tensor(auc) else auc for auc in AUC_scores]\n",
    "  training_log[\"time\"] = [t.cpu().item() if torch.is_tensor(t) else t for t in times]\n",
    "\n",
    "\n",
    "  # Testing\n",
    "\n",
    "  test_losses, auc_score, aupr_score, accuracy = test(model, test_loader)\n",
    "  test_results[\"test_loss\"] = test_losses.cpu().item() if torch.is_tensor(test_losses) else test_losses\n",
    "  test_results[\"accuracy\"] = accuracy.cpu().item() if torch.is_tensor(accuracy) else accuracy\n",
    "  test_results[\"AUPRC\"] = aupr_score.cpu().item() if torch.is_tensor(aupr_score) else aupr_score\n",
    "  test_results[\"AUROC\"] = auc_score.cpu().item() if torch.is_tensor(auc_score) else auc_score\n",
    "\n",
    "  # Save results\n",
    "\n",
    "  # UNCOMMENT BELOW IF INTENDING TO SAVE RESULTS\n",
    "\n",
    "  # train_fp = save_path+f\"split_{split}/training_log.csv\"\n",
    "  # training_log.to_csv(train_fp, index=False)\n",
    "\n",
    "  # test_fp = save_path+f\"split_{split}/test_results.json\"\n",
    "  # json_results = json.dumps(test_results, indent=4)\n",
    "  # with open(test_fp, 'w') as file:\n",
    "  #   file.write(json_results)\n",
    "\n",
    "  print(f\"Successfully saved data fromm split: {split}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
