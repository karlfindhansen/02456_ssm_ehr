{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionClassifier(nn.Module):\n",
    "    def __init__(self, ts_feature_dim, static_feature_dim, hidden_dim, num_classes):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            ts_feature_dim (int): Number of features in time-series data (e.g., 37).\n",
    "            static_feature_dim (int): Number of features in static data (e.g., 8).\n",
    "            hidden_dim (int): Dimension of hidden states in the model.\n",
    "            num_classes (int): Number of output classes (e.g., 2 for binary classification).\n",
    "        \"\"\"\n",
    "        super(AttentionClassifier, self).__init__()\n",
    "\n",
    "        # Time-series processing layers\n",
    "        self.ts_rnn = nn.LSTM(\n",
    "            input_size=ts_feature_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )  # Bidirectional LSTM for time-series features\n",
    "\n",
    "        # Static feature processing\n",
    "        self.static_fc = nn.Linear(static_feature_dim, hidden_dim)\n",
    "\n",
    "        # Attention layer to weight time-series features\n",
    "        self.attention = nn.Linear(hidden_dim * 2, 1)  # Bi-LSTM has 2*hidden_dim output\n",
    "\n",
    "        # Fully connected layers for classification\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2 + hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, ts_values, ts_indicators, ts_time, static):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            ts_values (torch.Tensor): Time-series data (batch_size, seq_len, ts_feature_dim).\n",
    "            ts_indicators (torch.Tensor): Indicator for missing time-series data (batch_size, seq_len, ts_feature_dim).\n",
    "            static (torch.Tensor): Static features (batch_size, static_feature_dim).\n",
    "        Returns:\n",
    "            torch.Tensor: Class probabilities (batch_size, num_classes).\n",
    "        \"\"\"\n",
    "        # Ensure the shape of ts_indicators matches ts_values\n",
    "        assert ts_values.shape == ts_indicators.shape, \"Shape mismatch between ts_values and ts_indicators\"\n",
    "        \n",
    "        # Handle missing data: Mask out the missing time-series values using ts_indicators\n",
    "        ts_values = ts_values * ts_indicators  # Element-wise multiplication to mask missing data\n",
    "\n",
    "        ts_time = ts_time.unsqueeze(-1)  # (batch_size, seq_len, 1)\n",
    "        ts_combined = torch.cat([ts_values, ts_time], dim=-1)  # (batch_size, seq_len, ts_feature_dim + 1)\n",
    "\n",
    "\n",
    "        # Process time-series data with LSTM\n",
    "        ts_encoded, _ = self.ts_rnn(ts_combined)  # ts_encoded: (batch_size, seq_len, hidden_dim*2)\n",
    "\n",
    "        # Compute attention weights over time steps (dim=1)\n",
    "        attn_weights = F.softmax(self.attention(ts_encoded), dim=1)  # (batch_size, seq_len, 1)\n",
    "\n",
    "        # Apply attention weights to the LSTM output, but only over the time steps\n",
    "        ts_attended = torch.sum(attn_weights * ts_encoded, dim=1)  # (batch_size, hidden_dim*2)\n",
    "\n",
    "        # Process static features\n",
    "        static_encoded = F.relu(self.static_fc(static))  # (batch_size, hidden_dim)\n",
    "\n",
    "        # Concatenate attended time-series and static features\n",
    "        combined = torch.cat([ts_attended, static_encoded], dim=1)  # (batch_size, hidden_dim*3)\n",
    "\n",
    "        # Classification\n",
    "        output = self.classifier(combined)  # (batch_size, num_classes)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def custom_collate_fn(batch):\n",
    "    ts_values = [sample[0].clone().detach().float() for sample in batch]\n",
    "    ts_indicators = [sample[1].clone().detach().float() for sample in batch]\n",
    "    ts_time = [sample[2].clone().detach().float() for sample in batch]\n",
    "    static = torch.stack([sample[3].clone().detach().float() for sample in batch])\n",
    "    labels = torch.tensor([sample[4] for sample in batch], dtype=torch.float32)\n",
    "\n",
    "\n",
    "    # Pad ts_values and ts_indicators\n",
    "    ts_values_padded = pad_sequence(ts_values, batch_first=True)\n",
    "    ts_indicators_padded = pad_sequence(ts_indicators, batch_first=True)\n",
    "\n",
    "    return ts_values_padded, ts_indicators_padded, static, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to handle batches with variable-length time-series data and static features.\n",
    "    \n",
    "    Args:\n",
    "        batch (list of tuples): Each tuple contains (ts_values, ts_indicators, ts_time, static, labels).\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Padded time-series values, indicators, times, static features, and labels.\n",
    "    \"\"\"\n",
    "    ts_values = [sample[0].clone().detach().float() for sample in batch]\n",
    "    ts_indicators = [sample[1].clone().detach().float() for sample in batch]\n",
    "    ts_times = [sample[2].clone().detach().float() for sample in batch]\n",
    "    static = torch.stack([sample[3].clone().detach().float() for sample in batch])\n",
    "    labels = torch.tensor([sample[4] for sample in batch], dtype=torch.float32)\n",
    "\n",
    "    # Pad ts_values, ts_indicators, and ts_time\n",
    "    ts_values_padded = pad_sequence(ts_values, batch_first=True)\n",
    "    ts_indicators_padded = pad_sequence(ts_indicators, batch_first=True)\n",
    "    ts_times_padded = pad_sequence(ts_times, batch_first=True)\n",
    "\n",
    "    return ts_values_padded, ts_indicators_padded, ts_times_padded, static, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ICUTimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        return (\n",
    "            torch.tensor(sample['ts_values'], dtype=torch.float32),  # Time-series values\n",
    "            torch.tensor(sample['ts_indicators'], dtype=torch.float32),  # Missing indicators\n",
    "            torch.tensor(sample['ts_times'], dtype=torch.float32),  # Time steps\n",
    "            torch.tensor(sample['static'], dtype=torch.float32),  # Static features\n",
    "            torch.tensor(sample['labels'], dtype=torch.float32)  # Label\n",
    "        )\n",
    "\n",
    "# Create train, validation, and test datasets\n",
    "train_data = np.load('Data/P12Data_1/split_1/train_physionet2012_1.npy', allow_pickle=True)\n",
    "test_data = np.load('Data/P12Data_1/split_1/test_physionet2012_1.npy', allow_pickle=True)\n",
    "val_data = np.load('Data/P12Data_1/split_1/validation_physionet2012_1.npy', allow_pickle=True)\n",
    "\n",
    "train_dataset = ICUTimeSeriesDataset(train_data)\n",
    "val_dataset = ICUTimeSeriesDataset(val_data)\n",
    "test_dataset = ICUTimeSeriesDataset(test_data)\n",
    "\n",
    "# Dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.4365\n",
      "Epoch [2/10], Loss: 0.2594\n",
      "Epoch [3/10], Loss: 0.2410\n",
      "Epoch [4/10], Loss: 0.2922\n",
      "Epoch [5/10], Loss: 0.3249\n",
      "Epoch [6/10], Loss: 0.3173\n",
      "Epoch [7/10], Loss: 0.5327\n",
      "Epoch [8/10], Loss: 0.3559\n",
      "Epoch [9/10], Loss: 0.2313\n",
      "Epoch [10/10], Loss: 0.2953\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Define model\n",
    "model = AttentionClassifier(\n",
    "    ts_feature_dim=38,\n",
    "    static_feature_dim=8,\n",
    "    hidden_dim=64,\n",
    "    num_classes=2\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):  # Adjust epochs as needed\n",
    "    model.train()\n",
    "    for ts_values, ts_indicators, ts_time, static, labels in train_loader:\n",
    "        ts_values,ts_indicators, ts_time , static, labels = ts_values.to(device), ts_indicators.to(device), ts_time.to(device), static.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(ts_values, ts_indicators, ts_time, static)\n",
    "        loss = criterion(outputs, labels.long())\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/10], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 85.24%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation loop\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for ts_values, ts_indicators, ts_time, static, labels in val_loader:\n",
    "        ts_values,ts_indicators,ts_time, static, labels = ts_values.to(device), ts_indicators.to(device),ts_time.to(device), static.to(device), labels.to(device)\n",
    "        outputs = model(ts_values, ts_indicators,ts_time, static)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.long()).sum().item()\n",
    "\n",
    "    print(f\"Validation Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the given data loader and calculates evaluation metrics.\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): Trained model.\n",
    "        data_loader (torch.utils.data.DataLoader): Data loader for validation/test set.\n",
    "        device (torch.device): Device to perform computation on (CPU/GPU).\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing evaluation metrics.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_prob = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for ts_values, ts_indicators, ts_time, static, labels in data_loader:\n",
    "            # Move data to device\n",
    "            ts_values,ts_indicators, ts_time, static, labels = ts_values.to(device), ts_indicators.to(device), ts_time.to(device), static.to(device), labels.to(device)\n",
    "            \n",
    "            # Get model predictions\n",
    "            outputs = model(ts_values, ts_indicators, ts_time, static)  # Raw logits\n",
    "            probabilities = torch.softmax(outputs, dim=1)[:, 1]  # Probability for class 1\n",
    "            predictions = torch.argmax(outputs, dim=1)  # Predicted class labels\n",
    "            \n",
    "            # Collect predictions and ground truth\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predictions.cpu().numpy())\n",
    "            y_prob.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=1)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=1)\n",
    "    roc_auc = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "    return {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-Score\": f1,\n",
    "        \"ROC-AUC\": roc_auc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8524\n",
      "Precision: 0.5909\n",
      "Recall: 0.2694\n",
      "F1-Score: 0.3701\n",
      "ROC-AUC: 0.8475\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the validation or test set\n",
    "metrics = evaluate_model(model, val_loader, device)\n",
    "\n",
    "# Print metrics\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
